{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open('data_cleaned.json') as json_file:\n",
    "    data_all = json.load(json_file)\n",
    "# Extract the keys in sorted order\n",
    "keys_all = sorted(data_all)\n",
    "# Convert python list to np array\n",
    "keys_all = np.asarray(keys_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = glob.glob('dataset/*')\n",
    "# Define global variables\n",
    "NUM_OF_PARTICIPANTS = len(participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment to Use PCA for dimensionality reduction\n",
    "# # features_all_scaled = ((features_all - features_all.mean(axis=0))/features_all.std(axis=0))\n",
    "\n",
    "# n_comp = 32\n",
    "# pca = PCA(n_components=n_comp)\n",
    "# pca.fit(encodings_all)\n",
    "\n",
    "# # ipca = IncrementalPCA(n_components=n_comp)\n",
    "# # ipca.fit(features_all_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_classifier = svm.SVC(C=10, kernel='rbf', gamma='scale')\n",
    "# features_train, features_val, labels_train, labels_val = train_test_split(features_all, labels_all, test_size=0.3)\n",
    "\n",
    "# svm_classifier.fit(features_train, labels_train)\n",
    "\n",
    "# y_pred_svm = svm_classifier.predict(features_val)\n",
    "\n",
    "# print('Training set accuracy for SVM:', svm_classifier.score(features_train, labels_train))\n",
    "# print('Test set accuracy for SVM: ', metrics.accuracy_score(labels_val, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('uuid_lengths_128.json') as json_file:\n",
    "    uuid_lengths = json.load(json_file)\n",
    "\n",
    "uuids = []\n",
    "sum = 0\n",
    "for i in range(NUM_OF_PARTICIPANTS):\n",
    "    uuid = participants[i].split('/')[1]\n",
    "    uuids.append(uuid)\n",
    "    sum += uuid_lengths[uuid]\n",
    "DATASET_SIZE = sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 TEST SVM: 0.52, TRAIN SVM: 0.89\n",
      "[[15  0]\n",
      " [16  2]]\n",
      "#1 TEST SVM: 0.77, TRAIN SVM: 0.89\n",
      "[[ 2  7]\n",
      " [ 0 22]]\n",
      "#2 TEST SVM: 0.55, TRAIN SVM: 0.89\n",
      "[[ 0 10]\n",
      " [ 0 12]]\n",
      "#3 TEST SVM: 0.69, TRAIN SVM: 0.89\n",
      "[[4 0]\n",
      " [4 5]]\n",
      "#4 TEST SVM: 0.5, TRAIN SVM: 0.89\n",
      "[[6 0]\n",
      " [8 2]]\n",
      "#5 TEST SVM: 0.83, TRAIN SVM: 0.89\n",
      "[[47  2]\n",
      " [15 35]]\n",
      "#6 TEST SVM: 1.0, TRAIN SVM: 0.89\n",
      "[[18  0]\n",
      " [ 0 24]]\n",
      "#7 TEST SVM: 0.48, TRAIN SVM: 0.88\n",
      "[[ 1 48]\n",
      " [ 0 44]]\n",
      "#8 TEST SVM: 0.86, TRAIN SVM: 0.89\n",
      "[[32  0]\n",
      " [11 35]]\n",
      "#9 TEST SVM: 0.73, TRAIN SVM: 0.89\n",
      "[[ 0 18]\n",
      " [ 0 49]]\n",
      "#10 TEST SVM: 0.52, TRAIN SVM: 0.89\n",
      "[[ 0 32]\n",
      " [ 0 34]]\n",
      "#11 TEST SVM: 0.69, TRAIN SVM: 0.88\n",
      "[[ 8 15]\n",
      " [ 0 25]]\n",
      "#12 TEST SVM: 0.92, TRAIN SVM: 0.89\n",
      "[[24  2]\n",
      " [ 2 24]]\n",
      "#13 TEST SVM: 0.46, TRAIN SVM: 0.89\n",
      "[[ 2  0]\n",
      " [13  9]]\n",
      "#14 TEST SVM: 0.89, TRAIN SVM: 0.88\n",
      "[[19  3]\n",
      " [ 2 23]]\n",
      "#15 TEST SVM: 0.68, TRAIN SVM: 0.88\n",
      "[[18 29]\n",
      " [ 2 48]]\n",
      "#16 TEST SVM: 0.75, TRAIN SVM: 0.89\n",
      "[[ 6 13]\n",
      " [ 2 39]]\n",
      "#17 TEST SVM: 0.92, TRAIN SVM: 0.89\n",
      "[[21  3]\n",
      " [ 2 37]]\n",
      "#18 TEST SVM: 0.5, TRAIN SVM: 0.89\n",
      "[[ 1 46]\n",
      " [ 0 45]]\n",
      "#19 TEST SVM: 0.7, TRAIN SVM: 0.89\n",
      "[[10 15]\n",
      " [ 0 25]]\n",
      "#20 TEST SVM: 0.56, TRAIN SVM: 0.88\n",
      "[[ 5 39]\n",
      " [ 0 44]]\n",
      "#21 TEST SVM: 0.87, TRAIN SVM: 0.88\n",
      "[[38  8]\n",
      " [ 4 43]]\n",
      "#22 TEST SVM: 0.65, TRAIN SVM: 0.89\n",
      "[[ 1  7]\n",
      " [ 0 12]]\n",
      "#23 TEST SVM: 0.81, TRAIN SVM: 0.89\n",
      "[[ 3  6]\n",
      " [ 0 22]]\n",
      "#24 TEST SVM: 0.0, TRAIN SVM: 0.89\n",
      "[[0 1]\n",
      " [0 0]]\n",
      "#25 TEST SVM: 0.51, TRAIN SVM: 0.88\n",
      "[[50  0]\n",
      " [49  1]]\n",
      "#26 TEST SVM: 0.68, TRAIN SVM: 0.89\n",
      "[[16 28]\n",
      " [ 1 45]]\n",
      "#27 TEST SVM: 0.52, TRAIN SVM: 0.89\n",
      "[[26  0]\n",
      " [24  0]]\n",
      "#28 TEST SVM: 0.97, TRAIN SVM: 0.88\n",
      "[[21  1]\n",
      " [ 0 13]]\n",
      "#29 TEST SVM: 0.88, TRAIN SVM: 0.89\n",
      "[[12  5]\n",
      " [ 0 25]]\n",
      "#30 TEST SVM: 0.9, TRAIN SVM: 0.88\n",
      "[[ 0  3]\n",
      " [ 0 26]]\n",
      "#31 TEST SVM: 0.75, TRAIN SVM: 0.89\n",
      "[[ 3  5]\n",
      " [ 0 12]]\n",
      "#32 TEST SVM: 0.27, TRAIN SVM: 0.88\n",
      "[[13  0]\n",
      " [40  2]]\n",
      "#33 TEST SVM: 0.47, TRAIN SVM: 0.89\n",
      "[[ 0 31]\n",
      " [ 0 27]]\n",
      "#34 TEST SVM: 0.76, TRAIN SVM: 0.89\n",
      "[[ 2  8]\n",
      " [ 0 24]]\n",
      "#35 TEST SVM: 0.8, TRAIN SVM: 0.89\n",
      "[[29  7]\n",
      " [ 9 34]]\n",
      "#36 TEST SVM: 0.53, TRAIN SVM: 0.88\n",
      "[[36  2]\n",
      " [39 10]]\n",
      "#37 TEST SVM: 0.35, TRAIN SVM: 0.89\n",
      "[[17  0]\n",
      " [31  0]]\n",
      "#38 TEST SVM: 0.5, TRAIN SVM: 0.89\n",
      "[[ 9  1]\n",
      " [10  2]]\n",
      "#39 TEST SVM: 1.0, TRAIN SVM: 0.88\n",
      "[[16]]\n",
      "#40 TEST SVM: 0.51, TRAIN SVM: 0.89\n",
      "[[ 1 19]\n",
      " [ 2 21]]\n",
      "#41 TEST SVM: 0.73, TRAIN SVM: 0.89\n",
      "[[ 4  7]\n",
      " [ 6 32]]\n",
      "#42 TEST SVM: 0.67, TRAIN SVM: 0.88\n",
      "[[ 5 11]\n",
      " [ 0 17]]\n",
      "#43 TEST SVM: 0.5, TRAIN SVM: 0.89\n",
      "[[ 0 25]\n",
      " [ 0 25]]\n",
      "#44 TEST SVM: 0.58, TRAIN SVM: 0.89\n",
      "[[ 0  8]\n",
      " [ 0 11]]\n",
      "#45 TEST SVM: 0.45, TRAIN SVM: 0.89\n",
      "[[18  5]\n",
      " [21  3]]\n",
      "#46 TEST SVM: 0.92, TRAIN SVM: 0.89\n",
      "[[13  3]\n",
      " [ 0 24]]\n",
      "#47 TEST SVM: 0.63, TRAIN SVM: 0.89\n",
      "[[ 5 15]\n",
      " [ 1 22]]\n",
      "#48 TEST SVM: 0.83, TRAIN SVM: 0.89\n",
      "[[10  0]\n",
      " [ 4  9]]\n",
      "#49 TEST SVM: 0.75, TRAIN SVM: 0.89\n",
      "[[18  1]\n",
      " [10 15]]\n",
      "#50 TEST SVM: 0.57, TRAIN SVM: 0.89\n",
      "[[13  9]\n",
      " [11 14]]\n",
      "#51 TEST SVM: 0.71, TRAIN SVM: 0.89\n",
      "[[16 20]\n",
      " [ 4 42]]\n",
      "0.6702412868632708\n"
     ]
    }
   ],
   "source": [
    "# Accuracy metrics for the whole dataset. These are computed\n",
    "# by leaving every Subject out one time, calculating the accuracy for each\n",
    "# one and then taking the mean value.\n",
    "# accuracy_rf_total = 0\n",
    "accuracy_svm_total = 0\n",
    "# precision_rf_total = 0\n",
    "# precision_svm_total = 0\n",
    "# recall_rf_total = 0\n",
    "# recall_svm_total = 0\n",
    "\n",
    "\n",
    "# Array to keep track of subjects with low score\n",
    "# low_score_subjects_rf = []\n",
    "# low_score_subjects_svm = []\n",
    "\n",
    "num_features = 128\n",
    "\n",
    "dataset_len = 0\n",
    "# Loop over each participant\n",
    "for j in range(len(participants)):\n",
    "    \n",
    "    # Extract the UUID\n",
    "    uuid_excluded = uuids[j]\n",
    "    length_excluded = uuid_lengths[uuid_excluded]\n",
    "    \n",
    "    features_train = np.zeros((DATASET_SIZE  - length_excluded, num_features))\n",
    "    features_val = np.zeros((length_excluded, num_features))\n",
    "    labels_train = np.zeros(DATASET_SIZE - length_excluded)\n",
    "    labels_val = np.zeros(length_excluded)\n",
    "    \n",
    "    start = 0\n",
    "        \n",
    "    for i in range(NUM_OF_PARTICIPANTS):\n",
    "        uuid = uuids[i]\n",
    "        length = uuid_lengths[uuid]\n",
    "\n",
    "        features = np.load('encodings_128/encodings_' + uuid + '.npy')\n",
    "        labels = np.load('encodings_128/labels_' + uuid + '.npy')\n",
    "        \n",
    "#         features = pca.transform(features)\n",
    "                \n",
    "        if uuid == uuid_excluded:\n",
    "            if features.shape[0] != length:\n",
    "                print('Error')\n",
    "            features_val = features\n",
    "            labels_val = labels\n",
    "        else:\n",
    "            if features.shape[0] != length:\n",
    "                print('Error 2')\n",
    "                print(features.shape[0], length, j, i)\n",
    "                break\n",
    "            features_train[start : start + length] = features\n",
    "            labels_train[start : start + length] = labels\n",
    "            start += length\n",
    "    classifier = svm.SVC(C=10, kernel='rbf', gamma='scale', probability=True)\n",
    "    classifier.fit(features_train, labels_train)\n",
    "    \n",
    "    # Predict SVM with threshold at 0.3 instead of 0.5\n",
    "    threshold = 0.3\n",
    "    y_prob_svm = classifier.predict_proba(features_val)\n",
    "    y_pred_svm = (y_prob_svm[:, 1] >= threshold).astype(int)\n",
    "    \n",
    "#     classifier = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "#     classifier.fit(features_train, labels_train)\n",
    "#     y_pred_rf = rf_classifier.predict(features_val)\n",
    "\n",
    "    confusion_matrix_svm = metrics.confusion_matrix(labels_val, y_pred_svm)\n",
    "    \n",
    "    accuracy_svm_subject = metrics.accuracy_score(labels_val, y_pred_svm)\n",
    "    accuracy_svm_total += accuracy_svm_subject*y_pred_svm.shape[0]\n",
    "    dataset_len += y_pred_svm.shape[0]\n",
    "    \n",
    "    print('#{} TEST SVM: {}, TRAIN SVM: {}'.format(j, round(accuracy_svm_subject, 2),\n",
    "                                      round(classifier.score(features_train, labels_train), 2)))\n",
    "    print(confusion_matrix_svm)\n",
    "#     plot_learning_curve(classifier,'Learning Curve',  features_train, labels_train, cv=5)\n",
    "#     plt.show()\n",
    "print(accuracy_svm_total/dataset_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
