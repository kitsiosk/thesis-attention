{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-One-Subject-Out Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import glob\n",
    "import pickle\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Model points for SolvePnP\n",
    "We will approximate the 3D points of the following face parts with the correspoinding coordinates. This is a general model of the human face and we do not need to worry much about absolute accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solvepnp_parameters(size, landmarks):\n",
    "    focal_length = size[1]\n",
    "    center = (size[1]/2, size[0]/2)\n",
    "    camera_matrix = np.array(\n",
    "                             [[focal_length, 0, center[0]],\n",
    "                             [0, focal_length, center[1]],\n",
    "                             [0, 0, 1]], dtype = \"double\"\n",
    "                             )\n",
    "\n",
    "    # Grab the 2D coordinates of our six sample points\n",
    "    image_points = np.array([\n",
    "        (landmarks[33]['x'], landmarks[33]['y']) ,     # Nose tip\n",
    "        (landmarks[8]['x'], landmarks[8]['y']),     # Chin\n",
    "        (landmarks[36]['x'], landmarks[36]['y']),     # Left eye left corner\n",
    "        (landmarks[45]['x'], landmarks[45]['y']),     # Right eye right corner\n",
    "        (landmarks[48]['x'], landmarks[48]['y']),     # Left Mouth corner\n",
    "        (landmarks[54]['x'], landmarks[54]['y'])      # Right mouth corner\n",
    "    ], dtype=\"double\")\n",
    "    \n",
    "    return image_points, camera_matrix\n",
    "\n",
    "# 3D model points.\n",
    "model_points = np.array([\n",
    "                            (0.0, 0.0, 0.0),             # Nose tip\n",
    "                            (0.0, -330.0, -65.0),        # Chin\n",
    "                            (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "                            (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "                            (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                            (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "                         \n",
    "                        ])\n",
    "\n",
    "dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(im, rotation_vector, translation_vector, image_points, camera_matrix):\n",
    "    # Project a 3D point (0, 0, 1000.0) onto the image plane.\n",
    "    # We use this to draw a line sticking out of the nose\n",
    "    (nose_end_point2D, jacobian) = cv2.projectPoints(\n",
    "        np.array([(0.0, 0.0, 500.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs\n",
    "        )\n",
    "    for p in image_points:\n",
    "        cv2.circle(im, (int(p[0]), int(p[1])), 3, (0,0,255), -1)\n",
    "    cv2.circle(im, (int(iris_left[0]), int(iris_left[1])), 3, (0, 0, 255), -1)\n",
    "    cv2.circle(im, (int(iris_right[0]), int(iris_right[1])), 3, (0, 0, 255), -1)\n",
    "    p1 = ( int(image_points[0][0]), int(image_points[0][1]) )\n",
    "    p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]) )\n",
    "\n",
    "    # Draw a line connecting the two points. This line must show\n",
    "    # the direction out of the nose\n",
    "    cv2.line(im, p1, p2, (255,0,0), 2)\n",
    "    # Display image\n",
    "    cv2.imshow(output, im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "participants = glob.glob('dataset/*')\n",
    "print(len(participants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2758\n"
     ]
    }
   ],
   "source": [
    "# Number of training examples to use(0-2758)\n",
    "DATASET_SIZE = 2758\n",
    "DEBUG = False\n",
    "\n",
    "# Load the dataset\n",
    "with open('data_cleaned.json') as json_file:\n",
    "    data_all = json.load(json_file)\n",
    "# Extract the keys in sorted order\n",
    "keys_all = sorted(data_all)\n",
    "# Convert python list to np array\n",
    "keys_all = np.asarray(keys_all)\n",
    "print(len(keys_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy for subject 0 with Random Forest: 0.6363636363636364\n",
      "Test set accuracy for subject 0 with SVM: 0.6666666666666666\n",
      "Test set accuracy for subject 1 with Random Forest: 0.9032258064516129\n",
      "Test set accuracy for subject 1 with SVM: 0.7741935483870968\n",
      "Test set accuracy for subject 2 with Random Forest: 0.8181818181818182\n",
      "Test set accuracy for subject 2 with SVM: 0.6818181818181818\n",
      "Test set accuracy for subject 3 with Random Forest: 0.46153846153846156\n",
      "Test set accuracy for subject 3 with SVM: 0.3076923076923077\n",
      "Test set accuracy for subject 4 with Random Forest: 0.0\n",
      "Test set accuracy for subject 4 with SVM: 0.3333333333333333\n",
      "Test set accuracy for subject 5 with Random Forest: 0.5\n",
      "Test set accuracy for subject 5 with SVM: 0.625\n",
      "Test set accuracy for subject 6 with Random Forest: 0.7474747474747475\n",
      "Test set accuracy for subject 6 with SVM: 0.7272727272727273\n",
      "Test set accuracy for subject 7 with Random Forest: 0.7727272727272727\n",
      "Test set accuracy for subject 7 with SVM: 0.4772727272727273\n",
      "Test set accuracy for subject 8 with Random Forest: 0.9139784946236559\n",
      "Test set accuracy for subject 8 with SVM: 0.8924731182795699\n",
      "Test set accuracy for subject 9 with Random Forest: 0.7564102564102564\n",
      "Test set accuracy for subject 9 with SVM: 0.6923076923076923\n",
      "Test set accuracy for subject 10 with Random Forest: 0.5970149253731343\n",
      "Test set accuracy for subject 10 with SVM: 0.5223880597014925\n",
      "Test set accuracy for subject 11 with Random Forest: 0.6363636363636364\n",
      "Test set accuracy for subject 11 with SVM: 0.6060606060606061\n",
      "Test set accuracy for subject 12 with Random Forest: 0.8958333333333334\n",
      "Test set accuracy for subject 12 with SVM: 0.6875\n",
      "Test set accuracy for subject 13 with Random Forest: 0.9230769230769231\n",
      "Test set accuracy for subject 13 with SVM: 0.8076923076923077\n",
      "Test set accuracy for subject 14 with Random Forest: 0.4074074074074074\n",
      "Test set accuracy for subject 14 with SVM: 0.4444444444444444\n",
      "Test set accuracy for subject 15 with Random Forest: 0.7659574468085106\n",
      "Test set accuracy for subject 15 with SVM: 0.7446808510638298\n",
      "Test set accuracy for subject 16 with Random Forest: 0.7525773195876289\n",
      "Test set accuracy for subject 16 with SVM: 0.7422680412371134\n",
      "Test set accuracy for subject 17 with Random Forest: 0.43548387096774194\n",
      "Test set accuracy for subject 17 with SVM: 0.4838709677419355\n",
      "Test set accuracy for subject 18 with Random Forest: 0.6666666666666666\n",
      "Test set accuracy for subject 18 with SVM: 0.5873015873015873\n",
      "Test set accuracy for subject 19 with Random Forest: 0.6630434782608695\n",
      "Test set accuracy for subject 19 with SVM: 0.7065217391304348\n",
      "Test set accuracy for subject 20 with Random Forest: 0.88\n",
      "Test set accuracy for subject 20 with SVM: 0.86\n",
      "Test set accuracy for subject 21 with Random Forest: 0.7916666666666666\n",
      "Test set accuracy for subject 21 with SVM: 0.7604166666666666\n",
      "Test set accuracy for subject 22 with Random Forest: 0.6559139784946236\n",
      "Test set accuracy for subject 22 with SVM: 0.5268817204301075\n",
      "Test set accuracy for subject 23 with Random Forest: 0.75\n",
      "Test set accuracy for subject 23 with SVM: 0.75\n",
      "Test set accuracy for subject 24 with Random Forest: 0.7058823529411765\n",
      "Test set accuracy for subject 24 with SVM: 0.6176470588235294\n",
      "Test set accuracy for subject 25 with Random Forest: 0.5833333333333334\n",
      "Test set accuracy for subject 25 with SVM: 0.5\n",
      "Test set accuracy for subject 26 with Random Forest: 0.89\n",
      "Test set accuracy for subject 26 with SVM: 0.75\n",
      "Test set accuracy for subject 27 with Random Forest: 0.6082474226804123\n",
      "Test set accuracy for subject 27 with SVM: 0.6701030927835051\n",
      "Test set accuracy for subject 28 with Random Forest: 0.46153846153846156\n",
      "Test set accuracy for subject 28 with SVM: 0.5576923076923077\n",
      "Test set accuracy for subject 29 with Random Forest: 0.6666666666666666\n",
      "Test set accuracy for subject 29 with SVM: 0.4722222222222222\n",
      "Test set accuracy for subject 30 with Random Forest: 0.5714285714285714\n",
      "Test set accuracy for subject 30 with SVM: 0.5952380952380952\n",
      "Test set accuracy for subject 31 with Random Forest: 0.5862068965517241\n",
      "Test set accuracy for subject 31 with SVM: 0.5517241379310345\n",
      "Test set accuracy for subject 32 with Random Forest: 0.5\n",
      "Test set accuracy for subject 32 with SVM: 0.5\n",
      "Test set accuracy for subject 33 with Random Forest: 0.85\n",
      "Test set accuracy for subject 33 with SVM: 0.7166666666666667\n",
      "Test set accuracy for subject 34 with Random Forest: 0.7777777777777778\n",
      "Test set accuracy for subject 34 with SVM: 0.7530864197530864\n",
      "Test set accuracy for subject 35 with Random Forest: 0.8235294117647058\n",
      "Test set accuracy for subject 35 with SVM: 0.7058823529411765\n",
      "Test set accuracy for subject 36 with Random Forest: 0.4444444444444444\n",
      "Test set accuracy for subject 36 with SVM: 0.45555555555555555\n",
      "Test set accuracy for subject 37 with Random Forest: 0.8522727272727273\n",
      "Test set accuracy for subject 37 with SVM: 0.7840909090909091\n",
      "Test set accuracy for subject 38 with Random Forest: 0.7466666666666667\n",
      "Test set accuracy for subject 38 with SVM: 0.7466666666666667\n",
      "Test set accuracy for subject 39 with Random Forest: 0.6363636363636364\n",
      "Test set accuracy for subject 39 with SVM: 0.45454545454545453\n",
      "Test set accuracy for subject 40 with Random Forest: 0.25\n",
      "Test set accuracy for subject 40 with SVM: 0.3125\n",
      "Test set accuracy for subject 41 with Random Forest: 0.5813953488372093\n",
      "Test set accuracy for subject 41 with SVM: 0.37209302325581395\n",
      "Test set accuracy for subject 42 with Random Forest: 0.5306122448979592\n",
      "Test set accuracy for subject 42 with SVM: 0.5918367346938775\n",
      "Test set accuracy for subject 43 with Random Forest: 0.4864864864864865\n",
      "Test set accuracy for subject 43 with SVM: 0.5405405405405406\n",
      "Test set accuracy for subject 44 with Random Forest: 0.66\n",
      "Test set accuracy for subject 44 with SVM: 0.68\n",
      "Test set accuracy for subject 45 with Random Forest: 0.5769230769230769\n",
      "Test set accuracy for subject 45 with SVM: 0.5\n",
      "Test set accuracy for subject 46 with Random Forest: 0.40425531914893614\n",
      "Test set accuracy for subject 46 with SVM: 0.5319148936170213\n",
      "Test set accuracy for subject 47 with Random Forest: 0.9\n",
      "Test set accuracy for subject 47 with SVM: 0.625\n",
      "Test set accuracy for subject 48 with Random Forest: 0.5333333333333333\n",
      "Test set accuracy for subject 48 with SVM: 0.4\n",
      "Test set accuracy for subject 49 with Random Forest: 0.7391304347826086\n",
      "Test set accuracy for subject 49 with SVM: 0.7391304347826086\n",
      "Test set accuracy for subject 50 with Random Forest: 0.6590909090909091\n",
      "Test set accuracy for subject 50 with SVM: 0.7045454545454546\n",
      "Test set accuracy for subject 51 with Random Forest: 0.5208333333333334\n",
      "Test set accuracy for subject 51 with SVM: 0.5833333333333334\n",
      "Test set accuracy for subject 52 with Random Forest: 0.5975609756097561\n",
      "Test set accuracy for subject 52 with SVM: 0.5609756097560976\n",
      "0.6849166062364032\n",
      "0.6443074691805656\n"
     ]
    }
   ],
   "source": [
    "# Accuracy metrics for the whole dataset. These are compouter\n",
    "# by leaving every Subject out one time, calculating the accuracy for each\n",
    "# one and then taking the mean.\n",
    "rf_accuracy = 0\n",
    "svm_accuracy = 0\n",
    "\n",
    "# Array to keep track of subjects with low score\n",
    "low_score_subjects_rf = []\n",
    "low_score_subjects_svm = []\n",
    "\n",
    "for j in range(len(participants)):\n",
    "    uuid_excluded = participants[j].split('/')[1]\n",
    "\n",
    "    indices_excluded = []\n",
    "    keys_excluded = []\n",
    "    for i in range(DATASET_SIZE):\n",
    "        key = keys_all[i]\n",
    "        uuid = key.split('/')[0]\n",
    "        if(uuid == uuid_excluded):\n",
    "            indices_excluded.append(i)\n",
    "            keys_excluded.append(key)\n",
    "    keys = np.delete(keys_all, indices_excluded)\n",
    "\n",
    "    CURRENT_DATASET_SIZE = keys.shape[0]\n",
    "\n",
    "    X = np.zeros((CURRENT_DATASET_SIZE, 14, 1))\n",
    "    y = np.zeros(CURRENT_DATASET_SIZE)\n",
    "\n",
    "    # Indices that the SolvePnP failed\n",
    "    failed_indices = []\n",
    "\n",
    "    for i in range(CURRENT_DATASET_SIZE):\n",
    "        key = keys[i]\n",
    "\n",
    "        # Approximate camera intrinsic parameters\n",
    "#         im = cv2.imread('dataset/' + key)   # This imread is time consuming! Another way?\n",
    "#         size = im.shape\n",
    "        with open('dataset/' + key.split('/')[0] + '/data.yml', 'r') as stream:\n",
    "            try:\n",
    "                laptop = yaml.safe_load(stream)['laptop']\n",
    "                if(laptop == 'k' or laptop == 'K'):\n",
    "                    size = (480, 640, 3)\n",
    "                elif(laptop == 'c' or laptop == 'C'):\n",
    "                    size = (720, 1280, 3)\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)\n",
    "\n",
    "        landmarks = data_all[key]['landmarks']\n",
    "        \n",
    "        image_points, camera_matrix = generate_solvepnp_parameters(size, landmarks)\n",
    "\n",
    "        # Solve the PnP problem with the parameters specified above\n",
    "        # and obtain rotation and translation vectors\n",
    "        (success, rotation_vector, translation_vector) = cv2.solvePnP(\n",
    "            model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_DLS\n",
    "            )\n",
    "        \n",
    "        # Data from Architecture #2. Reshape is done for compatibility reasons\n",
    "        iris_right = np.reshape(np.asarray(data_all[key]['iris_right']), (2, 1))\n",
    "        iris_left = np.reshape(np.asarray(data_all[key]['iris_left']), (2, 1))\n",
    "\n",
    "        # Data from Architecture #3\n",
    "        left_vector = np.asarray( (abs(iris_left[0] - landmarks[39]['x']), abs(iris_left[1] - landmarks[39]['y'])) )\n",
    "        right_vector = np.asarray( (abs(iris_right[0] - landmarks[42]['x']), abs(iris_right[1] - landmarks[42]['y'])) )\n",
    "\n",
    "        X[i, :] = np.concatenate((rotation_vector, translation_vector, iris_left, iris_right, \n",
    "                                 left_vector, right_vector), axis=0)\n",
    "\n",
    "        # Check if it is positive or negative example\n",
    "        output = key.split('/')[1]\n",
    "        if(output == 'positive'):\n",
    "            y[i] = 1\n",
    "        elif(output == 'negative'):\n",
    "            y[i] = 0\n",
    "    \n",
    "        # Remove examples that SolvePnP crashed\n",
    "        if(X[i, 0] > 10000):\n",
    "            print(key)\n",
    "            failed_indices.append(i)\n",
    "    X = np.delete(X, failed_indices, axis=0)\n",
    "    y = np.delete(y, failed_indices, axis=0)\n",
    "    \n",
    "    X = X.squeeze()\n",
    "\n",
    "    m = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    \n",
    "    X_scaled = (X - m)/std\n",
    "\n",
    "    ### Train and Predict\n",
    "\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.1)\n",
    "    X_train, y_train = X_scaled, y\n",
    "\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "#     y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "#     print('Test set accuracy for Random Forest: ', metrics.accuracy_score(y_test, y_pred_rf))\n",
    "\n",
    "    svm_classifier = svm.SVC(C=10, kernel='rbf', gamma='auto')\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "#     y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "#     print('Training set accuracy for SVM:', svm_classifier.score(X_train, y_train))\n",
    "#     print('Test set accuracy for SVM: ', metrics.accuracy_score(y_test, y_pred_svm))\n",
    "\n",
    "    X_eval = np.zeros((len(keys_excluded), 14, 1))\n",
    "    y_eval = np.zeros(len(keys_excluded))\n",
    "\n",
    "    for i in range(len(keys_excluded)):\n",
    "        key = keys_excluded[i]\n",
    "\n",
    "        # Approximate camera intrinsic parameters\n",
    "#         im = cv2.imread('dataset/' + key)   # This imread is time consuming! Another way?\n",
    "#         size = im.shape\n",
    "        with open('dataset/' + key.split('/')[0] + '/data.yml', 'r') as stream:\n",
    "            try:\n",
    "                laptop = yaml.safe_load(stream)['laptop']\n",
    "                if(laptop == 'k' or laptop == 'K'):\n",
    "                    size = (480, 640, 3)\n",
    "                elif(laptop == 'c' or laptop == 'C'):\n",
    "                    size = (720, 1280, 3)\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)\n",
    "\n",
    "        landmarks = data_all[key]['landmarks']\n",
    "        \n",
    "        image_points, camera_matrix = generate_solvepnp_parameters(size, landmarks)\n",
    "\n",
    "        # Solve the PnP problem with the parameters specified above\n",
    "        # and obtain rotation and translation vectors\n",
    "        (success, rotation_vector, translation_vector) = cv2.solvePnP(\n",
    "            model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_DLS\n",
    "            )\n",
    "\n",
    "        # Data from Architecture #2. Reshape is done for compatibility reasons\n",
    "        iris_right = np.reshape(np.asarray(data_all[key]['iris_right']), (2, 1))\n",
    "        iris_left = np.reshape(np.asarray(data_all[key]['iris_left']), (2, 1))\n",
    "\n",
    "        # Data from Architecture #3\n",
    "        left_vector = np.asarray( (abs(iris_left[0] - landmarks[39]['x']), abs(iris_left[1] - landmarks[39]['y'])) )\n",
    "        right_vector = np.asarray( (abs(iris_right[0] - landmarks[42]['x']), abs(iris_right[1] - landmarks[42]['y'])) )\n",
    "\n",
    "        X_eval[i, :] = np.concatenate((rotation_vector, translation_vector, iris_left, iris_right, \n",
    "                                      left_vector, right_vector), axis=0)\n",
    "\n",
    "        # Check if it is positive or negative example\n",
    "        output = key.split('/')[1]\n",
    "        if(output == 'positive'):\n",
    "            y_eval[i] = 1\n",
    "        elif(output == 'negative'):\n",
    "            y_eval[i] = 0\n",
    "\n",
    "    X_eval = X_eval.squeeze()\n",
    "#     print(X_eval.shape, y_eval.shape)\n",
    "\n",
    "    # Normalization\n",
    "    m_eval = X_eval.mean(axis=0)\n",
    "    std_eval = X_eval.std(axis=0)\n",
    "    X_eval = (X_eval - m_eval)/std_eval\n",
    "\n",
    "    # Predict Random Forest\n",
    "    y_eval_rf = rf_classifier.predict(X_eval)\n",
    "    rf_accuracy_subject = metrics.accuracy_score(y_eval, y_eval_rf)\n",
    "    print('Test set accuracy for subject {} with Random Forest: {}'.format(j, rf_accuracy_subject))\n",
    "\n",
    "    # Predict SVM\n",
    "    y_pred_svm = svm_classifier.predict(X_eval)\n",
    "    svm_accuracy_subject = metrics.accuracy_score(y_eval, y_pred_svm)\n",
    "    print('Test set accuracy for subject {} with SVM: {}'.format(j, svm_accuracy_subject))\n",
    "    \n",
    "    if(rf_accuracy_subject <= 0.5):\n",
    "        low_score_subjects_rf.append(uuid_excluded)\n",
    "    if(svm_accuracy_subject <= 0.5):\n",
    "        low_score_subjects_svm.append(uuid_excluded)\n",
    "    \n",
    "    rf_accuracy += rf_accuracy_subject*len(keys_excluded)\n",
    "    svm_accuracy += svm_accuracy_subject*len(keys_excluded)\n",
    "\n",
    "rf_accuracy = rf_accuracy/DATASET_SIZE\n",
    "svm_accuracy = svm_accuracy/DATASET_SIZE\n",
    "print(rf_accuracy)\n",
    "print(svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(low_score_subjects_rf))\n",
    "print(len(low_score_subjects_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"low_score_rf.txt\", \"w\") \n",
    "for i in low_score_subjects_rf:\n",
    "    file1.write(i + '\\n')\n",
    "    \n",
    "file2 = open(\"low_score_svm.txt\", \"w\")\n",
    "for i in low_score_subjects_svm:\n",
    "    file2.write(i + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
