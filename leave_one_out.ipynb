{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leave-One-Subject-Out Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import glob\n",
    "import pickle\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import yaml\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_parameters(size):\n",
    "    focal_length = size[1]\n",
    "    center = (size[1]/2, size[0]/2)\n",
    "    camera_matrix = np.array(\n",
    "                             [[focal_length, 0, center[0]],\n",
    "                             [0, focal_length, center[1]],\n",
    "                             [0, 0, 1]], dtype = \"double\"\n",
    "                             )\n",
    "    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "    \n",
    "    return camera_matrix, dist_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_image_points(landmarks):\n",
    "    image_points = np.zeros((68, 2))\n",
    "\n",
    "    for i in range(68):\n",
    "        image_points[i, :] = (landmarks[i]['x'], landmarks[i]['y'])\n",
    "    \n",
    "    return image_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_model_points(filename='model_points.txt'):\n",
    "    \"\"\"Get all 68 3D model points from file\"\"\"\n",
    "    raw_value = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            raw_value.append(line)\n",
    "    model_points = np.array(raw_value, dtype=np.float32)\n",
    "    model_points = np.reshape(model_points, (3, -1)).T\n",
    "\n",
    "    # Transform the model into a front view.\n",
    "    model_points[:, 2] *= -1\n",
    "\n",
    "    return model_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(im, rotation_vector, translation_vector, image_points, camera_matrix, dist_coeffs,\n",
    "                    iris_left, iris_right, label):\n",
    "    for point in image_points:\n",
    "        cv2.circle(im, (int(point[0]), int(point[1])), 3, (0, 0, 255), -1)\n",
    "    cv2.circle(im, (int(iris_left[0]), int(iris_left[1])), 3, (0, 0, 255), -1)\n",
    "    cv2.circle(im, (int(iris_right[0]), int(iris_right[1])), 3, (0, 0, 255), -1)\n",
    "    \n",
    "    # Project the 3D point (0.55592, 6.5629, 300.0) onto the image plane.\n",
    "    # We use this to draw a line sticking out of the nose\n",
    "    (nose_end_point2D, jacobian) = cv2.projectPoints(\n",
    "        np.array([(0.55592, 6.5629, 300.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs\n",
    "        )\n",
    "    # Draw a line connecting the two points. This line must show\n",
    "    # the direction out of the nose\n",
    "    p1 = ( int(image_points[33][0]), int(image_points[33][1]) )\n",
    "    p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]) )\n",
    "    cv2.line(im, p1, p2, (255,0,0), 2)\n",
    "    \n",
    "    # Display image\n",
    "    cv2.imshow(output, im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean([eye[1]['x'], eye[1]['y']], [eye[5]['x'], eye[5]['y']])\n",
    "    B = dist.euclidean([eye[2]['x'], eye[2]['y']], [eye[4]['x'], eye[4]['y']])\n",
    " \n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean([eye[0]['x'], eye[0]['y']], [eye[3]['x'], eye[3]['y']])\n",
    " \n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    " \n",
    "    # return the eye aspect ratio\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = glob.glob('dataset/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open('data_cleaned.json') as json_file:\n",
    "    data_all = json.load(json_file)\n",
    "# Extract the keys in sorted order\n",
    "keys_all = sorted(data_all)\n",
    "# Convert python list to np array\n",
    "keys_all = np.asarray(keys_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables\n",
    "DATASET_SIZE = len(keys_all)\n",
    "NUM_OF_PARTICIPANTS = len(participants)\n",
    "EAR_THRESHOLD = 0.17\n",
    "DEBUG = False\n",
    "MODEL_POINTS = get_full_model_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running attention prediction for 52 participants and a total of 2728 images.\n",
      "Each participant will be excluded from the training set once, our classifiers \n",
      "will be trained on the remaining participants and finally we will predict\n",
      "the result for the one we left out. The total accuracy will be the mean value\n",
      "of the accuracy of each participant\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Running attention prediction for {} participants and a total of {} images.\n",
    "Each participant will be excluded from the training set once, our classifiers \n",
    "will be trained on the remaining participants and finally we will predict\n",
    "the result for the one we left out. The total accuracy will be the mean value\n",
    "of the accuracy of each participant\"\"\".format(NUM_OF_PARTICIPANTS, DATASET_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF  #0 Accuracy: 0.697 | Precision: 0.9 | Recall: 0.53\n",
      "SVM #0 Accuracy: 0.818 | Precision: 0.93 | Recall: 0.76\n",
      "RF  #1 Accuracy: 0.806 | Precision: 0.94 | Recall: 0.77\n",
      "SVM #1 Accuracy: 0.871 | Precision: 0.95 | Recall: 0.86\n",
      "RF  #2 Accuracy: 0.864 | Precision: 0.85 | Recall: 0.92\n",
      "SVM #2 Accuracy: 0.818 | Precision: 0.83 | Recall: 0.83\n",
      "RF  #3 Accuracy: 0.692 | Precision: 0.78 | Recall: 0.78\n",
      "SVM #3 Accuracy: 0.462 | Precision: 0.62 | Recall: 0.56\n",
      "RF  #4 Accuracy: 0.676 | Precision: 0.86 | Recall: 0.55\n",
      "SVM #4 Accuracy: 0.703 | Precision: 0.76 | Recall: 0.73\n",
      "RF  #5 Accuracy: 0.788 | Precision: 0.78 | Recall: 0.8\n",
      "SVM #5 Accuracy: 0.818 | Precision: 0.79 | Recall: 0.88\n",
      "RF  #6 Accuracy: 0.81 | Precision: 1.0 | Recall: 0.67\n",
      "SVM #6 Accuracy: 0.738 | Precision: 0.81 | Recall: 0.71\n",
      "RF  #7 Accuracy: 0.871 | Precision: 0.94 | Recall: 0.77\n",
      "SVM #7 Accuracy: 0.892 | Precision: 0.92 | Recall: 0.84\n",
      "RF  #8 Accuracy: 0.962 | Precision: 1.0 | Recall: 0.93\n",
      "SVM #8 Accuracy: 0.962 | Precision: 0.96 | Recall: 0.98\n",
      "RF  #9 Accuracy: 0.627 | Precision: 0.96 | Recall: 0.52\n",
      "SVM #9 Accuracy: 0.701 | Precision: 0.87 | Recall: 0.71\n",
      "RF  #10 Accuracy: 0.697 | Precision: 0.69 | Recall: 0.74\n",
      "SVM #10 Accuracy: 0.712 | Precision: 0.67 | Recall: 0.85\n",
      "RF  #11 Accuracy: 0.833 | Precision: 0.95 | Recall: 0.72\n",
      "SVM #11 Accuracy: 0.792 | Precision: 0.89 | Recall: 0.68\n",
      "RF  #12 Accuracy: 0.923 | Precision: 0.96 | Recall: 0.88\n",
      "SVM #12 Accuracy: 0.846 | Precision: 0.85 | Recall: 0.85\n",
      "RF  #13 Accuracy: 0.6 | Precision: 1.0 | Recall: 0.6\n",
      "SVM #13 Accuracy: 0.84 | Precision: 1.0 | Recall: 0.9\n",
      "RF  #14 Accuracy: 0.851 | Precision: 0.91 | Recall: 0.8\n",
      "SVM #14 Accuracy: 0.851 | Precision: 0.88 | Recall: 0.84\n",
      "RF  #15 Accuracy: 0.794 | Precision: 0.84 | Recall: 0.8\n",
      "SVM #15 Accuracy: 0.866 | Precision: 0.85 | Recall: 0.98\n",
      "RF  #16 Accuracy: 0.483 | Precision: 0.73 | Recall: 0.39\n",
      "SVM #16 Accuracy: 0.667 | Precision: 0.78 | Recall: 0.71\n",
      "RF  #17 Accuracy: 0.587 | Precision: 0.88 | Recall: 0.5\n",
      "SVM #17 Accuracy: 0.635 | Precision: 0.81 | Recall: 0.7\n",
      "RF  #18 Accuracy: 0.761 | Precision: 0.81 | Recall: 0.67\n",
      "SVM #18 Accuracy: 0.63 | Precision: 0.59 | Recall: 0.78\n",
      "RF  #19 Accuracy: 0.94 | Precision: 0.96 | Recall: 0.92\n",
      "SVM #19 Accuracy: 0.8 | Precision: 0.74 | Recall: 0.92\n",
      "RF  #20 Accuracy: 0.76 | Precision: 0.74 | Recall: 0.82\n",
      "SVM #20 Accuracy: 0.823 | Precision: 0.8 | Recall: 0.88\n",
      "RF  #21 Accuracy: 0.817 | Precision: 0.8 | Recall: 0.85\n",
      "SVM #21 Accuracy: 0.763 | Precision: 0.73 | Recall: 0.85\n",
      "RF  #22 Accuracy: 0.85 | Precision: 0.91 | Recall: 0.83\n",
      "SVM #22 Accuracy: 0.9 | Precision: 0.92 | Recall: 0.92\n",
      "RF  #23 Accuracy: 0.882 | Precision: 1.0 | Recall: 0.82\n",
      "SVM #23 Accuracy: 0.971 | Precision: 1.0 | Recall: 0.95\n",
      "RF  #24 Accuracy: 0.583 | Precision: 0.5 | Recall: 0.8\n",
      "SVM #24 Accuracy: 0.667 | Precision: 0.6 | Recall: 0.6\n",
      "RF  #25 Accuracy: 0.9 | Precision: 1.0 | Recall: 0.82\n",
      "SVM #25 Accuracy: 0.85 | Precision: 0.89 | Recall: 0.82\n",
      "RF  #26 Accuracy: 0.639 | Precision: 0.64 | Recall: 0.68\n",
      "SVM #26 Accuracy: 0.742 | Precision: 0.7 | Recall: 0.88\n",
      "RF  #27 Accuracy: 0.66 | Precision: 0.65 | Recall: 0.62\n",
      "SVM #27 Accuracy: 0.7 | Precision: 0.7 | Recall: 0.67\n",
      "RF  #28 Accuracy: 0.657 | Precision: 0.54 | Recall: 0.54\n",
      "SVM #28 Accuracy: 0.686 | Precision: 0.57 | Recall: 0.62\n",
      "RF  #29 Accuracy: 0.738 | Precision: 0.94 | Recall: 0.62\n",
      "SVM #29 Accuracy: 0.833 | Precision: 0.95 | Recall: 0.79\n",
      "RF  #30 Accuracy: 0.69 | Precision: 1.0 | Recall: 0.65\n",
      "SVM #30 Accuracy: 0.828 | Precision: 1.0 | Recall: 0.81\n",
      "RF  #31 Accuracy: 0.65 | Precision: 0.86 | Recall: 0.5\n",
      "SVM #31 Accuracy: 0.6 | Precision: 0.83 | Recall: 0.42\n",
      "RF  #32 Accuracy: 0.9 | Precision: 1.0 | Recall: 0.87\n",
      "SVM #32 Accuracy: 0.85 | Precision: 0.98 | Recall: 0.83\n",
      "RF  #33 Accuracy: 0.778 | Precision: 0.83 | Recall: 0.78\n",
      "SVM #33 Accuracy: 0.704 | Precision: 0.7 | Recall: 0.81\n",
      "RF  #34 Accuracy: 0.647 | Precision: 0.75 | Recall: 0.75\n",
      "SVM #34 Accuracy: 0.882 | Precision: 0.92 | Recall: 0.92\n",
      "RF  #35 Accuracy: 0.771 | Precision: 0.89 | Recall: 0.67\n",
      "SVM #35 Accuracy: 0.735 | Precision: 0.8 | Recall: 0.7\n",
      "RF  #36 Accuracy: 0.864 | Precision: 0.89 | Recall: 0.86\n",
      "SVM #36 Accuracy: 0.841 | Precision: 0.82 | Recall: 0.92\n",
      "RF  #37 Accuracy: 0.84 | Precision: 0.92 | Recall: 0.8\n",
      "SVM #37 Accuracy: 0.84 | Precision: 0.85 | Recall: 0.89\n",
      "RF  #38 Accuracy: 0.591 | Precision: 0.67 | Recall: 0.5\n",
      "SVM #38 Accuracy: 0.636 | Precision: 0.7 | Recall: 0.58\n",
      "RF  #39 Accuracy: 0.562 | Precision: 1.0 | Recall: 0.56\n",
      "SVM #39 Accuracy: 0.562 | Precision: 1.0 | Recall: 0.56\n",
      "RF  #40 Accuracy: 0.558 | Precision: 0.7 | Recall: 0.3\n",
      "SVM #40 Accuracy: 0.651 | Precision: 0.67 | Recall: 0.7\n",
      "RF  #41 Accuracy: 0.592 | Precision: 0.88 | Recall: 0.55\n",
      "SVM #41 Accuracy: 0.755 | Precision: 0.86 | Recall: 0.82\n",
      "RF  #42 Accuracy: 0.606 | Precision: 0.64 | Recall: 0.53\n",
      "SVM #42 Accuracy: 0.576 | Precision: 0.57 | Recall: 0.71\n",
      "RF  #43 Accuracy: 0.64 | Precision: 0.82 | Recall: 0.36\n",
      "SVM #43 Accuracy: 0.66 | Precision: 0.75 | Recall: 0.48\n",
      "RF  #44 Accuracy: 0.5 | Precision: 0.67 | Recall: 0.5\n",
      "SVM #44 Accuracy: 0.542 | Precision: 0.75 | Recall: 0.5\n",
      "RF  #45 Accuracy: 0.532 | Precision: 0.55 | Recall: 0.46\n",
      "SVM #45 Accuracy: 0.596 | Precision: 0.6 | Recall: 0.62\n",
      "RF  #46 Accuracy: 0.9 | Precision: 0.95 | Recall: 0.88\n",
      "SVM #46 Accuracy: 0.75 | Precision: 0.89 | Recall: 0.67\n",
      "RF  #47 Accuracy: 0.628 | Precision: 0.64 | Recall: 0.7\n",
      "SVM #47 Accuracy: 0.744 | Precision: 0.71 | Recall: 0.87\n",
      "RF  #48 Accuracy: 0.957 | Precision: 1.0 | Recall: 0.92\n",
      "SVM #48 Accuracy: 0.87 | Precision: 1.0 | Recall: 0.77\n",
      "RF  #49 Accuracy: 0.977 | Precision: 0.96 | Recall: 1.0\n",
      "SVM #49 Accuracy: 0.682 | Precision: 0.92 | Recall: 0.48\n",
      "RF  #50 Accuracy: 0.729 | Precision: 0.75 | Recall: 0.72\n",
      "SVM #50 Accuracy: 0.708 | Precision: 0.79 | Recall: 0.6\n",
      "RF  #51 Accuracy: 0.622 | Precision: 0.69 | Recall: 0.6\n",
      "SVM #51 Accuracy: 0.573 | Precision: 0.61 | Recall: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Accuracy metrics for the whole dataset. These are compouted\n",
    "# by leaving every Subject out one time, calculating the accuracy for each\n",
    "# one and then taking the mean value.\n",
    "accuracy_rf_total = 0\n",
    "accuracy_svm_total = 0\n",
    "precision_rf_total = 0\n",
    "precision_svm_total = 0\n",
    "recall_rf_total = 0\n",
    "recall_svm_total = 0\n",
    "\n",
    "\n",
    "# Array to keep track of subjects with low score\n",
    "low_score_subjects_rf = []\n",
    "low_score_subjects_svm = []\n",
    "\n",
    "# Loop over each participant\n",
    "for j in range(NUM_OF_PARTICIPANTS):\n",
    "    \n",
    "    # Extract the UUID\n",
    "    uuid_excluded = participants[j].split('/')[1]\n",
    "\n",
    "    # Loop over the dataset to remove the examples associated with this participant\n",
    "    indices_excluded = []\n",
    "    keys_excluded = []\n",
    "    for i in range(DATASET_SIZE):\n",
    "        key = keys_all[i]\n",
    "        uuid = key.split('/')[0]\n",
    "        if(uuid == uuid_excluded):\n",
    "            indices_excluded.append(i)\n",
    "            keys_excluded.append(key)\n",
    "#     keys = np.delete(keys_all, indices_excluded)\n",
    "#     CURRENT_DATASET_SIZE = keys.shape[0]\n",
    "\n",
    "#     # Initialize our training dataset\n",
    "#     X = np.zeros((CURRENT_DATASET_SIZE, 14, 1))\n",
    "#     y = np.zeros(CURRENT_DATASET_SIZE)\n",
    "\n",
    "#     # Indices that the SolvePnP failed\n",
    "#     failed_indices = []\n",
    "#     # Indices where the subject blinked\n",
    "#     blinked_indices = []\n",
    "    \n",
    "#     # Loop over each example to construct the training dataset. \n",
    "#     for i in range(CURRENT_DATASET_SIZE):\n",
    "        \n",
    "#         # Retrieve the key for this example\n",
    "#         key = keys[i]\n",
    "        \n",
    "#         # Read the image and save the size\n",
    "#         im = cv2.imread('dataset/' + key)\n",
    "#         size = im.shape\n",
    "            \n",
    "#         # Get the 68 facial landmarks\n",
    "#         landmarks = data_all[key]['landmarks']\n",
    "        \n",
    "#         # Use the above landmarks to generate image points in the \n",
    "#         # form that solvePnP() takes as input\n",
    "#         image_points = get_full_image_points(landmarks)\n",
    "        \n",
    "#         # Get camera parameters to feed into solvePnP()\n",
    "#         camera_matrix, dist_coeffs = get_camera_parameters(size)\n",
    "\n",
    "#         # Solve the PnP problem with the parameters specified above\n",
    "#         # and obtain rotation and translation vectors\n",
    "#         (success, rotation_vector, translation_vector) = cv2.solvePnP(\n",
    "#             MODEL_POINTS, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE\n",
    "#             )\n",
    "        \n",
    "#         # Iris location features\n",
    "#         iris_right = np.reshape(np.asarray(data_all[key]['iris_right']), (2, 1))\n",
    "#         iris_left = np.reshape(np.asarray(data_all[key]['iris_left']), (2, 1))\n",
    "\n",
    "#         # Difference vector features\n",
    "#         left_vector = np.asarray( (abs(iris_left[0] - landmarks[39]['x']), abs(iris_left[1] - landmarks[39]['y'])) )\n",
    "#         right_vector = np.asarray( (abs(iris_right[0] - landmarks[42]['x']), abs(iris_right[1] - landmarks[42]['y'])) )\n",
    "        \n",
    "#         # Concatenate all the above features to create a training example\n",
    "#         X[i, :] = np.concatenate((rotation_vector, translation_vector, iris_left, iris_right, \n",
    "#                                  left_vector, right_vector), axis=0)\n",
    "\n",
    "#         # Check if it is positive or negative example and set the groundtruth value accordingly\n",
    "#         output = key.split('/')[1]\n",
    "#         if(output == 'positive'):\n",
    "#             y[i] = 1\n",
    "#         elif(output == 'negative'):\n",
    "#             y[i] = 0\n",
    "    \n",
    "#         # Blink Detection\n",
    "#         leftEAR = eye_aspect_ratio(landmarks[36:42])\n",
    "#         rightEAR = eye_aspect_ratio(landmarks[42:48])\n",
    "#         ear = (leftEAR + rightEAR) / 2.0\n",
    "#         if(ear <= EAR_THRESHOLD):\n",
    "#             blinked_indices.append(i)\n",
    "            \n",
    "#         # Remove examples that SolvePnP crashed\n",
    "#         if(X[i, 0] > 10000 or not success):\n",
    "#             print(key)\n",
    "#             failed_indices.append(i)\n",
    "            \n",
    "#     # Delete indices that solvePnP failed to solve correctly\n",
    "#     X = np.delete(X, failed_indices, axis=0)\n",
    "#     y = np.delete(y, failed_indices, axis=0)\n",
    "#     # Blink detection: Remove the blinked examples\n",
    "#     X = np.delete(X, blinked_indices, axis=0)\n",
    "#     y = np.delete(y, blinked_indices, axis=0)\n",
    "    \n",
    "#     # Reshape for compatibility reasons\n",
    "#     X = X.squeeze()\n",
    "    \n",
    "#     # Normalize features to have 0 mean and 1 variance\n",
    "#     m = X.mean(axis=0)\n",
    "#     std = X.std(axis=0)\n",
    "#     X_scaled = (X - m)/std\n",
    "    \n",
    "#     ### Train the classifiers\n",
    "#     X_train, y_train = X_scaled, y\n",
    "\n",
    "#     rf_classifier = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "#     rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "#     svm_classifier = svm.SVC(C=10, kernel='rbf', gamma='scale', probability=True)\n",
    "#     svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# ### Uncomment to save classifiers in pickle files so there is no need to train every time\n",
    "#     with open('classifiers/rf/' + uuid_excluded + '.pickle', 'wb') as f:\n",
    "#         pickle.dump(rf_classifier, f, pickle.HIGHEST_PROTOCOL)\n",
    "#     with open('classifiers/svm/' + uuid_excluded + '.pickle', 'wb') as f:\n",
    "#         pickle.dump(svm_classifier, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### Uncomment to retrieve classifiers from the saved pickle files\n",
    "    with open('classifiers/rf/' + uuid_excluded + '.pickle', 'rb') as f:\n",
    "        rf_classifier = pickle.load(f)\n",
    "    with open('classifiers/svm/' + uuid_excluded + '.pickle', 'rb') as f:\n",
    "        svm_classifier = pickle.load(f)\n",
    "\n",
    "\n",
    "    # Construct the validation dataset consisting of examples of a single participant\n",
    "    # Evaluation of the classifiers will be done on this dataset\n",
    "    X_eval = np.zeros((len(keys_excluded), 14, 1))\n",
    "    y_eval = np.zeros(len(keys_excluded))\n",
    "    \n",
    "    # Indices where the subject blinked\n",
    "    blinked_indices = []\n",
    "    \n",
    "    # Perform the same steps as the consturction of the training dataset\n",
    "    for i in range(len(keys_excluded)):\n",
    "        key = keys_excluded[i]\n",
    "\n",
    "        im = cv2.imread('dataset/' + key)\n",
    "        size = im.shape\n",
    "\n",
    "        landmarks = data_all[key]['landmarks']\n",
    "        \n",
    "        camera_matrix, dist_coeffs = get_camera_parameters(size)\n",
    "        \n",
    "        image_points = get_full_image_points(landmarks)\n",
    "\n",
    "        (success, rotation_vector, translation_vector) = cv2.solvePnP(\n",
    "            MODEL_POINTS, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE\n",
    "            )\n",
    "\n",
    "        iris_right = np.reshape(np.asarray(data_all[key]['iris_right']), (2, 1))\n",
    "        iris_left = np.reshape(np.asarray(data_all[key]['iris_left']), (2, 1))\n",
    "        left_vector = np.asarray( (abs(iris_left[0] - landmarks[39]['x']), abs(iris_left[1] - landmarks[39]['y'])) )\n",
    "        right_vector = np.asarray( (abs(iris_right[0] - landmarks[42]['x']), abs(iris_right[1] - landmarks[42]['y'])) )\n",
    "\n",
    "        X_eval[i, :] = np.concatenate((rotation_vector, translation_vector, iris_left, iris_right, \n",
    "                                      left_vector, right_vector), axis=0)\n",
    "        \n",
    "        output = key.split('/')[1]\n",
    "        if(output == 'positive'):\n",
    "            y_eval[i] = 1\n",
    "        elif(output == 'negative'):\n",
    "            y_eval[i] = 0\n",
    "        \n",
    "        # Blink Detection\n",
    "        leftEAR = eye_aspect_ratio(landmarks[36:42])\n",
    "        rightEAR = eye_aspect_ratio(landmarks[42:48])\n",
    "        ear = (leftEAR + rightEAR) / 2.0\n",
    "        if(ear <= EAR_THRESHOLD):\n",
    "            blinked_indices.append(i)\n",
    "#             visualize_image(im, rotation_vector, translation_vector, image_points, camera_matrix,\n",
    "#                            dist_coeffs, iris_left, iris_right, output)\n",
    "\n",
    "    X_eval = X_eval.squeeze()\n",
    "    \n",
    "    # Number of the examples that we predicted a blink\n",
    "    predicted_blinks = len(blinked_indices)\n",
    "    # Counter that counts how many of the predicted blinks are true blinks\n",
    "    true_blinks = 0\n",
    "    # Loop over each predicted blink\n",
    "    for k in blinked_indices:\n",
    "        # If the groundtruth is Negative our prediction was true\n",
    "        if y_eval[k] == 0:\n",
    "            true_blinks += 1\n",
    "\n",
    "    # Remove the blinked examples\n",
    "    X_eval = np.delete(X_eval, blinked_indices, axis=0)\n",
    "    y_eval = np.delete(y_eval, blinked_indices, axis=0)\n",
    "    \n",
    "    # Feature Normalization\n",
    "    m_eval = X_eval.mean(axis=0)\n",
    "    std_eval = X_eval.std(axis=0)\n",
    "    X_eval = (X_eval - m_eval)/std_eval\n",
    "\n",
    "    # Predict Random Forest\n",
    "    y_pred_rf = rf_classifier.predict(X_eval)\n",
    "    rf_accuracy_subject = metrics.accuracy_score(y_eval, y_pred_rf)\n",
    "    # For the overall accuracy of each subject we must take into consideration the blink accuracy too\n",
    "    rf_accuracy_subject = (rf_accuracy_subject*X_eval.shape[0] + true_blinks)/(X_eval.shape[0] + predicted_blinks)\n",
    "\n",
    "    # Predict SVM\n",
    "    threshold = 0.3\n",
    "    y_prob_svm = svm_classifier.predict_proba(X_eval)\n",
    "    y_pred_svm = (y_prob_svm[:, 1] >= threshold).astype(int)\n",
    "    svm_accuracy_subject = metrics.accuracy_score(y_eval, y_pred_svm)\n",
    "    svm_accuracy_subject = (svm_accuracy_subject*X_eval.shape[0] + true_blinks)/(X_eval.shape[0] + predicted_blinks)\n",
    "    \n",
    "    # From the confusion matrix of the 2 classifiers calculate precision and recall\n",
    "    #### Note that the blinked examples will not be added here ----> FIX\n",
    "    confusion_matrix_rf = metrics.confusion_matrix(y_eval, y_pred_rf)\n",
    "    confusion_matrix_svm = metrics.confusion_matrix(y_eval, y_pred_svm)\n",
    "    precision_rf = confusion_matrix_rf[1][1]/(confusion_matrix_rf[1][1] + confusion_matrix_rf[0][1])\n",
    "    recall_rf = confusion_matrix_rf[1][1]/(confusion_matrix_rf[1][1] + confusion_matrix_rf[1][0])\n",
    "    precision_svm = confusion_matrix_svm[1][1]/(confusion_matrix_svm[1][1] + confusion_matrix_svm[0][1])\n",
    "    recall_svm = confusion_matrix_svm[1][1]/(confusion_matrix_svm[1][1] + confusion_matrix_svm[1][0])\n",
    "    \n",
    "    print('RF  #{} Accuracy: {} | Precision: {} | Recall: {}'.format(j, round(rf_accuracy_subject,3),\n",
    "                                                            round(precision_rf,2), round(recall_rf, 2)))\n",
    "    print('SVM #{} Accuracy: {} | Precision: {} | Recall: {}'.format(j, round(svm_accuracy_subject, 3),\n",
    "                                                            round(precision_svm, 2), round(recall_svm, 2)))\n",
    "    \n",
    "    # Keep track of the participants that performed poorly for debbuging purposes\n",
    "    if(rf_accuracy_subject <= 0.5):\n",
    "        low_score_subjects_rf.append(uuid_excluded)\n",
    "        with open('classifiers/rf/' + uuid_excluded + '.pickle', 'wb') as f:\n",
    "            pickle.dump(rf_classifier, f, pickle.HIGHEST_PROTOCOL)\n",
    "    if(svm_accuracy_subject <= 0.5):\n",
    "        low_score_subjects_svm.append(uuid_excluded)\n",
    "        with open('classifiers/svm/' + uuid_excluded + '.pickle', 'wb') as f:\n",
    "            pickle.dump(svm_classifier, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    # Calculate the total metrics by mulitiplying each metric with the\n",
    "    # number of examples of its dataset and in the end divide by\n",
    "    # the total number of examples\n",
    "    accuracy_rf_total += rf_accuracy_subject*len(keys_excluded)\n",
    "    accuracy_svm_total += svm_accuracy_subject*len(keys_excluded)\n",
    "    precision_rf_total += precision_rf*len(keys_excluded)\n",
    "    precision_svm_total += precision_svm*len(keys_excluded)\n",
    "    recall_rf_total += recall_rf*len(keys_excluded)\n",
    "    recall_svm_total += recall_svm*len(keys_excluded)\n",
    "    \n",
    "accuracy_rf_total /= DATASET_SIZE\n",
    "accuracy_svm_total /= DATASET_SIZE\n",
    "precision_rf_total /= DATASET_SIZE\n",
    "precision_svm_total /= DATASET_SIZE\n",
    "recall_rf_total /= DATASET_SIZE\n",
    "recall_svm_total /= DATASET_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy RF:  0.7532991202346041\n",
      "Total Accucary SVM: 0.7620967741935484\n"
     ]
    }
   ],
   "source": [
    "print('Total Accuracy RF:  {}'.format(accuracy_rf_total))\n",
    "print('Total Accucary SVM: {}'.format(accuracy_svm_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision RF: 0.8393611319728038\n",
      "Precision SVM: 0.8015463476106014\n"
     ]
    }
   ],
   "source": [
    "print('Precision RF: {}'.format(precision_rf_total))\n",
    "print('Precision SVM: {}'.format(precision_svm_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall RF: 0.7115066259967211\n",
      "Recall SVM: 0.7866064933277864\n"
     ]
    }
   ],
   "source": [
    "print('Recall RF: {}'.format(recall_rf_total))\n",
    "print('Recall SVM: {}'.format(recall_svm_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(low_score_subjects_rf))\n",
    "print(len(low_score_subjects_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"low_score_rf.txt\", \"w\") \n",
    "for i in low_score_subjects_rf:\n",
    "    file1.write(i + '\\n')\n",
    "    \n",
    "file2 = open(\"low_score_svm.txt\", \"w\")\n",
    "for i in low_score_subjects_svm:\n",
    "    file2.write(i + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
