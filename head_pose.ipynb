{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform facial landmark Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "Camera Matrix :\n",
      " [[640.   0. 320.]\n",
      " [  0. 640. 240.]\n",
      " [  0.   0.   1.]]\n",
      "Rotation Vector:\n",
      " [[-2.82303234]\n",
      " [ 0.07662005]\n",
      " [ 0.58571914]]\n",
      "Translation Vector:\n",
      " [[ -29.86482998]\n",
      " [ 125.23345586]\n",
      " [1667.60154487]]\n"
     ]
    }
   ],
   "source": [
    "# Read Image\n",
    "im = cv2.imread(\"test.jpg\");\n",
    "size = im.shape\n",
    "print(size)\n",
    "# Directory of the pretrained model\n",
    "p = \"shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "# Get faces into webcam's image\n",
    "rects = detector(im, 0)\n",
    "\n",
    "# Loop over every face detected. Here we only have on face each time\n",
    "for rect in rects:\n",
    "    # Make the prediction and transfom it to numpy array\n",
    "    shape = predictor(im, rect)\n",
    "    landmarks = face_utils.shape_to_np(shape)\n",
    "\n",
    "# Grab the 2D coordinates of our six sample points\n",
    "image_points = np.array([\n",
    "                            landmarks[33, :],     # Nose tip\n",
    "                            landmarks[8, :],     # Chin\n",
    "                            landmarks[36, :],     # Left eye left corner\n",
    "                            landmarks[45, :],     # Right eye right corner\n",
    "                            landmarks[48, :],     # Left Mouth corner\n",
    "                            landmarks[54, :]      # Right mouth corner\n",
    "                        ], dtype=\"double\")\n",
    "\n",
    "# 3D model points.\n",
    "model_points = np.array([\n",
    "                            (0.0, 0.0, 0.0),             # Nose tip\n",
    "                            (0.0, -330.0, -65.0),        # Chin\n",
    "                            (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "                            (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "                            (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                            (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "                         \n",
    "                        ])\n",
    "\n",
    "# Approximate camera intrinsic parameters\n",
    "focal_length = size[1]\n",
    "center = (size[1]/2, size[0]/2)\n",
    "camera_matrix = np.array(\n",
    "                         [[focal_length, 0, center[0]],\n",
    "                         [0, focal_length, center[1]],\n",
    "                         [0, 0, 1]], dtype = \"double\"\n",
    "                         )\n",
    "dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    " \n",
    "print(\"Camera Matrix :\\n {0}\".format(camera_matrix))\n",
    "\n",
    "# Solve the PnP problem with the parameters specified above\n",
    "(success, rotation_vector, translation_vector) = cv2.solvePnP(\n",
    "    model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE\n",
    "    )\n",
    "\n",
    "print(\"Rotation Vector:\\n {0}\".format(rotation_vector))\n",
    "print(\"Translation Vector:\\n {0}\".format(translation_vector))\n",
    "\n",
    "# Project a 3D point (0, 0, 1000.0) onto the image plane.\n",
    "# We use this to draw a line sticking out of the nose\n",
    "(nose_end_point2D, jacobian) = cv2.projectPoints(\n",
    "    np.array([(0.0, 0.0, 500.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs\n",
    "    )\n",
    "\n",
    "for p in image_points:\n",
    "    cv2.circle(im, (int(p[0]), int(p[1])), 3, (0,0,255), -1)\n",
    "    \n",
    "p1 = ( int(image_points[0][0]), int(image_points[0][1]) )\n",
    "p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]) )\n",
    "\n",
    "# Draw a line connecting the two points. This line must show\n",
    "# the direction out of the nose\n",
    "cv2.line(im, p1, p2, (255,0,0), 2)\n",
    " \n",
    "# Display image\n",
    "cv2.imshow(\"Output\", im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "# In the beggining we will use the rotation and translation of each face as input\n",
    "X = np.concatenate((rotation_vector, translation_vector), axis=1)\n",
    "print(X.shape)\n",
    "\n",
    "# The selected image is a 'looking' image\n",
    "y = np.ones(1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
