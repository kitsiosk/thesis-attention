{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_parameters(size):\n",
    "    focal_length = size[1]\n",
    "    center = (size[1]/2, size[0]/2)\n",
    "    camera_matrix = np.array(\n",
    "                             [[focal_length, 0, center[0]],\n",
    "                             [0, focal_length, center[1]],\n",
    "                             [0, 0, 1]], dtype = \"double\"\n",
    "                             )\n",
    "    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "    \n",
    "    return camera_matrix, dist_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_image_points(landmarks):\n",
    "    image_points = np.zeros((68, 2))\n",
    "\n",
    "    for i in range(68):\n",
    "        image_points[i, :] = (landmarks[i]['x'], landmarks[i]['y'])\n",
    "    \n",
    "    return image_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_model_points(filename='model_points.txt'):\n",
    "    \"\"\"Get all 68 3D model points from file\"\"\"\n",
    "    raw_value = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            raw_value.append(line)\n",
    "    model_points = np.array(raw_value, dtype=np.float32)\n",
    "    model_points = np.reshape(model_points, (3, -1)).T\n",
    "\n",
    "    # Transform the model into a front view.\n",
    "    model_points[:, 2] *= -1\n",
    "\n",
    "    return model_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(im, rotation_vector, translation_vector, image_points, camera_matrix, dist_coeffs,\n",
    "                    iris_right, iris_left, label):\n",
    "    for point in image_points:\n",
    "        cv2.circle(im, (int(point[0]), int(point[1])), 3, (0, 0, 255), -1)\n",
    "    cv2.circle(im, (int(iris_left[0]), int(iris_left[1])), 3, (255, 0, 0), -1)\n",
    "    cv2.circle(im, (int(iris_right[0]), int(iris_right[1])), 3, (255, 0, 0), -1)\n",
    "    \n",
    "    # Project the 3D point (0.55592, 6.5629, 300.0) onto the image plane.\n",
    "    # We use this to draw a line sticking out of the nose\n",
    "    (nose_end_point2D, jacobian) = cv2.projectPoints(\n",
    "        np.array([(0.55592, 6.5629, 300.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs\n",
    "        )\n",
    "    # Draw a line connecting the two points. This line must show\n",
    "    # the direction out of the nose\n",
    "    p1 = ( int(image_points[33][0]), int(image_points[33][1]) )\n",
    "    p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]) )\n",
    "    cv2.line(im, p1, p2, (255,0,0), 2)\n",
    "    \n",
    "    # Display image\n",
    "    cv2.imshow(label, im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean([eye[1]['x'], eye[1]['y']], [eye[5]['x'], eye[5]['y']])\n",
    "    B = dist.euclidean([eye[2]['x'], eye[2]['y']], [eye[4]['x'], eye[4]['y']])\n",
    " \n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean([eye[0]['x'], eye[0]['y']], [eye[3]['x'], eye[3]['y']])\n",
    " \n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    " \n",
    "    # return the eye aspect ratio\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open('data_cleaned.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "# Extract the keys in sorted order\n",
    "keys_all = sorted(data)\n",
    "# Convert python list to np array\n",
    "keys_all = np.asarray(keys_all)\n",
    "DATASET_SIZE = 2728\n",
    "EAR_THRESHOLD = 0.2\n",
    "\n",
    "model_points = get_full_model_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples for this uuid: 47\n",
      "18 18\n",
      "Accuracy: 0.7446808510638298\n",
      "[[ 4  1]\n",
      " [11 13]]\n"
     ]
    }
   ],
   "source": [
    "# for uuid in uuids[0:1]:\n",
    "# # Remove the newline character\n",
    "# uuid = uuid[:-1]\n",
    "# print('UUID: ' + uuid)\n",
    "uuid = '0e7047653b014264b33c1c3620e506f8'\n",
    "\n",
    "with open('classifiers/rf/' + uuid + '.pickle', 'rb') as f:\n",
    "    svm_classifier = pickle.load(f)\n",
    "# with open('classifiers/svm/' + uuid +'.pickle', 'rb') as f:\n",
    "#     svm_classifier = pickle.load(f)\n",
    "\n",
    "# Array of keys for this uuid\n",
    "keys = []\n",
    "for i in range(DATASET_SIZE):\n",
    "    key = keys_all[i]\n",
    "    if(key.split('/')[0] == uuid):\n",
    "        keys.append(key)\n",
    "print('Number of examples for this uuid: {}'.format(len(keys)))\n",
    "\n",
    "X = np.zeros((len(keys), 14, 1))\n",
    "# X = [[]]\n",
    "y = np.zeros(len(keys))\n",
    "\n",
    "blinked_indices = []\n",
    "valid_keys = []\n",
    "\n",
    "for i in range(len(keys)):\n",
    "    key = keys[i]\n",
    "    im = cv2.imread('dataset/' + key)   # This imread is time consuming! Another way?\n",
    "    size = im.shape\n",
    "\n",
    "    landmarks = data[key]['landmarks']\n",
    "\n",
    "    camera_matrix, dist_coeffs = get_camera_parameters(size)\n",
    "    \n",
    "    image_points = get_full_image_points(landmarks)\n",
    "\n",
    "    # Solve the PnP problem with the parameters specified above\n",
    "    # and obtain rotation and translation vectors\n",
    "    (success, rotation_vector, translation_vector) = cv2.solvePnP(\n",
    "        model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_EPNP\n",
    "        )\n",
    "\n",
    "    # Data from Architecture #2. Reshape is done for compatibility reasons\n",
    "    iris_right = np.reshape(np.asarray(data[key]['iris_right']), (2, 1))\n",
    "    iris_left = np.reshape(np.asarray(data[key]['iris_left']), (2, 1))\n",
    "\n",
    "    # Data from Architecture #3\n",
    "    left_vector = np.asarray( (abs(iris_left[0] - landmarks[39]['x']), abs(iris_left[1] - landmarks[39]['y'])) )\n",
    "    right_vector = np.asarray( (abs(iris_right[0] - landmarks[42]['x']), abs(iris_right[1] - landmarks[42]['y'])) )\n",
    "\n",
    "    X[i, :] = np.concatenate((rotation_vector, translation_vector, iris_left, iris_right, \n",
    "                             left_vector, right_vector), axis=0)\n",
    "\n",
    "#     iris_right = (data[key]['iris_right'])\n",
    "#     iris_left = (data[key]['iris_left'])\n",
    "#     left_vector = [abs(iris_left[0] - landmarks[39]['x']), abs(iris_left[1] - landmarks[39]['y'])]\n",
    "#     right_vector = [abs(iris_right[0] - landmarks[42]['x']), abs(iris_right[1] - landmarks[42]['y'])]\n",
    "#     X.append( rotation_vector.tolist() + translation_vector.tolist() + iris_left + iris_right + left_vector + right_vector )\n",
    "    \n",
    "    # Check if it is positive or negative example\n",
    "    output = key.split('/')[1]\n",
    "    if(output == 'positive'):\n",
    "        y[i] = 1\n",
    "    elif(output == 'negative'):\n",
    "        y[i] = 0\n",
    "    \n",
    "    # Blink Detection\n",
    "    leftEAR = eye_aspect_ratio(landmarks[36:42])\n",
    "    rightEAR = eye_aspect_ratio(landmarks[42:48])\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    if(ear <= EAR_THRESHOLD):\n",
    "        blinked_indices.append(i)\n",
    "    else:\n",
    "        valid_keys.append(key)\n",
    "\n",
    "\n",
    "predicted_blinks = len(blinked_indices)\n",
    "true_blinks = 0\n",
    "for k in blinked_indices:\n",
    "    if y[k] == 0:\n",
    "        true_blinks += 1\n",
    "        \n",
    "print(predicted_blinks, true_blinks)\n",
    "\n",
    "X_val = np.delete(X, blinked_indices, axis=0)\n",
    "y_val = np.delete(y, blinked_indices, axis=0)\n",
    "\n",
    "X_val = X_val.squeeze()\n",
    "\n",
    "m = X_val.mean(axis=0)\n",
    "std = X_val.std(axis=0)\n",
    "X_scaled = (X_val-m)/std\n",
    "\n",
    "y_pred = svm_classifier.predict(X_scaled)\n",
    "classifier_accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "accuracy = (classifier_accuracy*X_val.shape[0] + true_blinks)/(X_val.shape[0] + predicted_blinks)\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "print(metrics.confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False  True False  True  True  True  True  True\n",
      " False  True False  True False False  True False False False False False\n",
      "  True  True False False False]\n"
     ]
    }
   ],
   "source": [
    "failed_indices = (y_val != y_pred)\n",
    "print((failed_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(failed_indices)):\n",
    "    if failed_indices[i]:\n",
    "        key = valid_keys[i]\n",
    "        label = key.split('/')[1]\n",
    "        im = cv2.imread('dataset/' + key)\n",
    "        size = im.shape\n",
    "        \n",
    "        landmarks = data[key]['landmarks']\n",
    "        image_points = get_full_image_points(landmarks)\n",
    "        camera_matrix, dist_coeffs = get_camera_parameters(size)\n",
    "        \n",
    "        visualize_image(im, X_val[i, 0:3], X_val[i, 3:6], image_points, camera_matrix, dist_coeffs, X_val[i, 6:8], X_val[i, 8:10], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negatives:\n",
      "2.8192101992093512\n",
      "3.25477203956018\n",
      "2.6060781478881836\n",
      "2.746704725118775\n",
      "0.3236083617577208\n",
      "2.879357924828156\n",
      "2.0970065410320444\n",
      "2.22178151057318\n",
      "1.7875318894019472\n",
      "2.3511106050931403\n",
      "2.700253706711976\n",
      "2.539508196023803\n",
      "2.940511263333832\n",
      "0.9772604062006849\n",
      "1.9619749509371331\n",
      "2.6457295784583437\n",
      "3.406033515930176\n",
      "0.8055892724257205\n",
      "4.744444443629334\n",
      "1.307962564321656\n",
      "4.023964184981139\n",
      "2.4465326896080626\n",
      "2.6731181511512148\n",
      "2.45136345349826\n",
      "0.5634184617262576\n",
      "2.108732223510742\n",
      "1.6958942413330078\n",
      "2.09460126436673\n",
      "0.5055019305302721\n",
      "4.2833295968862615\n",
      "0.24755804355328337\n",
      "True negatives:\n",
      "1.2932024002075195\n",
      "1.4774847764235233\n",
      "0.8276224869948123\n",
      "0.8783782078669446\n",
      "0.6298829592191169\n",
      "2.037371378678529\n",
      "1.7213633610651868\n",
      "1.569537492898803\n",
      "1.846873466785155\n",
      "0.880313946650574\n"
     ]
    }
   ],
   "source": [
    "print('False negatives:')\n",
    "for i in range(len(failed_indices)):\n",
    "    if y[i] == 1 and y_pred[i]==0:\n",
    "        print(X[i, 10])\n",
    "print('True negatives:')\n",
    "for i in range(len(failed_indices)):\n",
    "    if y[i] == 1 and y_pred[i]==1:\n",
    "        print(X[i, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "a = [[j for j in range(14)] for i in range(100000)]\n",
    "end = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1812627369999973\n"
     ]
    }
   ],
   "source": [
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
