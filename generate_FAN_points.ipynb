{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import face_recognition\n",
    "import math\n",
    "import face_alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open('data_cleaned.json') as json_file:\n",
    "    data_all = json.load(json_file)\n",
    "# Extract the keys in sorted order\n",
    "keys_all = sorted(data_all)\n",
    "# Convert python list to np array\n",
    "keys_all = np.asarray(keys_all)\n",
    "\n",
    "# with open('uuid_lengths_128.json') as json_file:\n",
    "#     uuid_lengths_128 = json.load(json_file)\n",
    "\n",
    "participants = glob.glob('dataset/*')\n",
    "# participants = sorted(participants)\n",
    "    \n",
    "DATASET_SIZE = len(keys_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa2D = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=False, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa3D = face_alignment.FaceAlignment(face_alignment.LandmarksType._3D, flip_input=False, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each participant\n",
    "uuid_lengths_FAN = {}\n",
    "fail_counter = 0\n",
    "for j in range(1):\n",
    "    \n",
    "    # Extract the UUID\n",
    "    uuid_excluded = participants[j].split('/')[1]\n",
    "\n",
    "    # Loop over the dataset to remove the examples associated with this participant\n",
    "    indices_excluded = []\n",
    "    keys_excluded = []\n",
    "    for i in range(DATASET_SIZE):\n",
    "        key = keys_all[i]\n",
    "        uuid = key.split('/')[0]\n",
    "        if(uuid == uuid_excluded):\n",
    "\n",
    "            indices_excluded.append(i)\n",
    "            keys_excluded.append(key)\n",
    "    \n",
    "    # Construct the validation dataset consisting of examples of a single participant\n",
    "    # Evaluation of the classifiers will be done on this dataset\n",
    "    image_points = np.zeros((len(keys_excluded), 68, 2))\n",
    "    model_points = np.zeros((len(keys_excluded), 68, 3))\n",
    "    labels = np.zeros(len(keys_excluded))\n",
    "    \n",
    "    failed_indices = []\n",
    "    for i in range(len(keys_excluded)):\n",
    "        key = keys_excluded[i]\n",
    "        label = key.split('/')[1]\n",
    "\n",
    "        im = cv2.imread('dataset/' + key)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        im_points = np.asarray(fa2D.get_landmarks(im))\n",
    "        mod_points = np.asarray(fa3D.get_landmarks(im))\n",
    "        if(im_points.shape != (68, 2)):\n",
    "            max_dist = 0\n",
    "            max_idx = 0\n",
    "            i = 0\n",
    "            while(i < im_points.shape[0]):\n",
    "                if(abs(im_points[i, 8, 1] - im_points[i, 27, 1]) > max_dist):\n",
    "                    max_dist = abs(im_points[i, 8, 1] - im_points[i, 27, 1])\n",
    "                    max_idx = i\n",
    "                i += 1\n",
    "            im_points = im_points[max_idx, :]\n",
    "            mod_points = mod_points[max_idx, :]\n",
    "            \n",
    "        image_points[i, :] = im_points.reshape(68, 2)\n",
    "        model_points[i, :] = mod_points.reshape(68, 3)\n",
    "        if(label=='positive'):\n",
    "            labels[i] = 1\n",
    "        else:\n",
    "            labels[i] = 0\n",
    "#         for point in image_points[0, :]:\n",
    "#             cv2.circle(im, (int(point[0]), int(point[1])), 3, (0, 0, 255), -1)\n",
    "#         cv2.imshow('Test', im)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "    \n",
    "    uuid_lengths_FAN[uuid_excluded] = labels.shape[0]\n",
    "    np.save('FAN_landmarks_kitsios/image_points_' + uuid_excluded , image_points)\n",
    "    np.save('FAN_landmarks_kitsios/model_points_' + uuid_excluded, model_points)\n",
    "    np.save('FAN_landmarks_kitsios/labels_' + uuid_excluded, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
