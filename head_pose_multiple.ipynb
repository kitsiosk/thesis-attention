{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import glob\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pretrained Dlib model for face landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory of the pretrained model\n",
    "p = \"shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# Pretrained dlib model\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "\n",
    "# Change hardcoded size\n",
    "size = (480, 640, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the 3D points in World Coordinates. These will be the same for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D model points.\n",
    "model_points = np.array([\n",
    "                            (0.0, 0.0, 0.0),             # Nose tip\n",
    "                            (0.0, -330.0, -65.0),        # Chin\n",
    "                            (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "                            (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "                            (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                            (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "                         \n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate Camera Intrinsic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate camera intrinsic parameters\n",
    "focal_length = size[1]\n",
    "center = (size[1]/2, size[0]/2)\n",
    "camera_matrix = np.array(\n",
    "                         [[focal_length, 0, center[0]],\n",
    "                         [0, focal_length, center[1]],\n",
    "                         [0, 0, 1]], dtype = \"double\"\n",
    "                         )\n",
    "dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "[[[-2.92169335e+00]\n",
      "  [ 3.42095614e-02]\n",
      "  [-3.62215831e-01]\n",
      "  [ 1.62104510e+02]\n",
      "  [ 8.87853615e+01]\n",
      "  [ 2.17018419e+03]]\n",
      "\n",
      " [[-2.97798950e+00]\n",
      "  [ 4.78704725e-02]\n",
      "  [-3.29580993e-01]\n",
      "  [ 1.42695668e+02]\n",
      "  [ 5.19086824e+01]\n",
      "  [ 2.17032161e+03]]\n",
      "\n",
      " [[-2.92621287e+00]\n",
      "  [ 1.84997323e-02]\n",
      "  [-3.70240819e-01]\n",
      "  [ 1.71627464e+02]\n",
      "  [ 8.96016943e+01]\n",
      "  [ 2.13865282e+03]]\n",
      "\n",
      " [[-2.78627228e+00]\n",
      "  [-2.86201073e-03]\n",
      "  [-5.00350785e-01]\n",
      "  [ 1.33310575e+02]\n",
      "  [ 1.07916371e+02]\n",
      "  [ 1.99295840e+03]]\n",
      "\n",
      " [[-2.91673205e+00]\n",
      "  [ 2.25644603e-02]\n",
      "  [-2.25882268e-01]\n",
      "  [ 1.68212931e+02]\n",
      "  [ 6.29700273e+01]\n",
      "  [ 2.15535384e+03]]]\n"
     ]
    }
   ],
   "source": [
    "files_positive = glob.glob('test_dataset/positive/*.jpg')\n",
    "files_negative = glob.glob('test_dataset/negative/*.jpg')\n",
    "\n",
    "X = np.zeros((52, 6, 1))\n",
    "\n",
    "for i in range(len(files_positive) + len(files_negative)):\n",
    "    if i<len(files_positive):\n",
    "        image = cv2.imread(files_positive[i])\n",
    "    else:\n",
    "        image = cv2.imread(files_negative[i-26])\n",
    "    \n",
    "    # Get faces into webcam's image\n",
    "    rects = detector(image, 0)\n",
    "\n",
    "    # Loop over every face detected. Here we only have on face each time\n",
    "    for rect in rects:\n",
    "        # Make the prediction and transfom it to numpy array\n",
    "        shape = predictor(image, rect)\n",
    "        landmarks = face_utils.shape_to_np(shape)\n",
    "        \n",
    "    # Grab the 2D coordinates of our six sample points\n",
    "    image_points = np.array([\n",
    "        landmarks[33, :],     # Nose tip\n",
    "        landmarks[8, :],     # Chin\n",
    "        landmarks[36, :],     # Left eye left corner\n",
    "        landmarks[45, :],     # Right eye right corner\n",
    "        landmarks[48, :],     # Left Mouth corner\n",
    "        landmarks[54, :]      # Right mouth corner\n",
    "    ], dtype=\"double\")\n",
    "\n",
    "    # Solve the PnP problem with the parameters specified above\n",
    "    (success, rotation_vector, translation_vector) = cv2.solvePnP(\n",
    "        model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE\n",
    "        )\n",
    "#     print(\"Rotation Vector:\\n {0}\".format(rotation_vector))\n",
    "#     print(\"Translation Vector:\\n {0}\".format(translation_vector))\n",
    "    \n",
    "    X[i, :] = np.concatenate((rotation_vector, translation_vector), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('input.out', X.squeeze(), delimiter=',')   # X is an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 6)\n"
     ]
    }
   ],
   "source": [
    "X = X.squeeze()\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52,)\n"
     ]
    }
   ],
   "source": [
    "y = np.concatenate((np.zeros((26)), np.ones((26))), axis=0)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('output.out', y, delimiter=',')   # X is an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [i for i in range(52)]\n",
    "shuffle(indexes)\n",
    "\n",
    "X = X[indexes, :]\n",
    "y = y[indexes, ]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8125\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
