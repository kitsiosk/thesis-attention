{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Familiarize with Dataset\n",
    "Run the following cells to see dataset images with the points used as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial import distance as dist\n",
    "import dlib\n",
    "from imutils import face_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 10\n",
    "\n",
    "with open('data_cleaned.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Convert python list to np array\n",
    "keys_all = sorted(data)\n",
    "keys_all = np.asarray(keys_all)\n",
    "rand_indices = np.random.randint(len(data), size=DATASET_SIZE)\n",
    "keys = keys_all[rand_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that returns the required parameters of the solvePnP method. The paramaters *model_points* and *dist_coeffs* are the same for every example so they are declared globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_parameters(size):\n",
    "    # Approximate camera intrinsic parameters\n",
    "    focal_length = size[1]\n",
    "    center = (size[1]/2, size[0]/2)\n",
    "    camera_matrix = np.array(\n",
    "                             [[focal_length, 0, center[0]],\n",
    "                             [0, focal_length, center[1]],\n",
    "                             [0, 0, 1]], dtype = \"double\"\n",
    "                             )\n",
    "    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "    \n",
    "    return camera_matrix, dist_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_image_points(landmarks):\n",
    "    image_points = np.zeros((68, 2))\n",
    "\n",
    "    for i in range(68):\n",
    "        image_points[i, :] = (landmarks[i]['x'], landmarks[i]['y'])\n",
    "    \n",
    "    return image_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_model_points(filename='model_points.txt'):\n",
    "    \"\"\"Get all 68 3D model points from file\"\"\"\n",
    "    raw_value = []\n",
    "    with open(filename) as file:\n",
    "        for line in file:\n",
    "            raw_value.append(line)\n",
    "    model_points = np.array(raw_value, dtype=np.float32)\n",
    "    model_points = np.reshape(model_points, (3, -1)).T\n",
    "\n",
    "    # Transform the model into a front view.\n",
    "    model_points[:, 2] *= -1\n",
    "\n",
    "    return model_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3D_reconstruction_points(name):\n",
    "    filename = '../PRNet/TestImages/AFLW2000_results/' + name + '_kpt.txt'\n",
    "    model_points = np.loadtxt(filename, dtype=np.float32)\n",
    "    for i in range(len(model_points)):\n",
    "        x = model_points[i][2]\n",
    "        y = model_points[i][1]\n",
    "        z = model_points[i][0]\n",
    "        model_points[i] = [x, y, z]\n",
    "    return model_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eye_aspect_ratio(eye):\n",
    "    # compute the euclidean distances between the two sets of\n",
    "    # vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean([eye[1]['x'], eye[1]['y']], [eye[5]['x'], eye[5]['y']])\n",
    "    B = dist.euclidean([eye[2]['x'], eye[2]['y']], [eye[4]['x'], eye[4]['y']])\n",
    " \n",
    "    # compute the euclidean distance between the horizontal\n",
    "    # eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean([eye[0]['x'], eye[0]['y']], [eye[3]['x'], eye[3]['y']])\n",
    " \n",
    "    # compute the eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    " \n",
    "    # return the eye aspect ratio\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the 3D model points for a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blink in key #9\n"
     ]
    }
   ],
   "source": [
    "model_points = get_full_model_points()\n",
    "\n",
    "for i in range(DATASET_SIZE):\n",
    "    key = keys[i]\n",
    "    im = cv2.imread('dataset/' + key)\n",
    "    \n",
    "    # Check if it is positive or negative example\n",
    "    output = key.split('/')[1]\n",
    "        \n",
    "    ex = data[key]\n",
    "    landmarks = ex['landmarks']\n",
    "    iris_left = ex['iris_left']\n",
    "    iris_right = ex['iris_right']\n",
    "    \n",
    "    # Change hardcoded size\n",
    "    size = im.shape\n",
    "    \n",
    "    camera_matrix, dist_coeffs = get_camera_parameters(size)\n",
    "\n",
    "    image_points = get_full_image_points(landmarks)\n",
    "\n",
    "    # Solve the PnP problem with the parameters specified above\n",
    "    (suc, rotation_vector, translation_vector) = cv2.solvePnP(\n",
    "        model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE\n",
    "        )\n",
    "    \n",
    "    #Blink Detection\n",
    "    leftEAR = eye_aspect_ratio(landmarks[36:42])\n",
    "    rightEAR = eye_aspect_ratio(landmarks[42:48])\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    \n",
    "    if(ear < 0.2):\n",
    "        print('Blink in key #{}'.format(i))\n",
    "    \n",
    "    for point in image_points:\n",
    "        cv2.circle(im, (int(point[0]), int(point[1])), 3, (0, 0, 255), -1)\n",
    "    cv2.circle(im, (int(iris_left[0]), int(iris_left[1])), 3, (0, 0, 255), -1)\n",
    "    cv2.circle(im, (int(iris_right[0]), int(iris_right[1])), 3, (0, 0, 255), -1)\n",
    "    \n",
    "    # Project the 3D point (0.55592, 6.5629, 300.0) onto the image plane.\n",
    "    # We use this to draw a line sticking out of the nose\n",
    "    (nose_end_point2D, jacobian) = cv2.projectPoints(\n",
    "        np.array([(0.55592, 6.5629, 300.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs\n",
    "        )\n",
    "    # Draw a line connecting the two points. This line must show\n",
    "    # the direction out of the nose\n",
    "    p1 = ( int(image_points[33][0]), int(image_points[33][1]) )\n",
    "    p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]) )\n",
    "    cv2.line(im, p1, p2, (255,0,0), 2)\n",
    "    \n",
    "    # Display image\n",
    "    cv2.imshow(output, im)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
