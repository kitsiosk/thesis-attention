{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, label):\n",
    "    cv2.imshow(label, image)\n",
    "    ans = cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/0656f5fe35a54d1589e526a702f578b0\n"
     ]
    }
   ],
   "source": [
    "participants = glob.glob('dataset/*')\n",
    "print(participants[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open('data_cleaned.json') as json_file:\n",
    "    data_all = json.load(json_file)\n",
    "# Extract the keys in sorted order\n",
    "keys_all = sorted(data_all)\n",
    "# Convert python list to np array\n",
    "keys_all = np.asarray(keys_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training examples to use(0-2758)\n",
    "DATASET_SIZE = len(keys_all)\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = np.zeros((DATASET_SIZE, 224, 224, 3))\n",
    "labels = np.zeros(DATASET_SIZE)\n",
    "uuids = []\n",
    "failed_keys = []\n",
    "\n",
    "for i in range(DATASET_SIZE):\n",
    "    key = keys_all[i]\n",
    "    im = cv2.imread('dataset/' + key)\n",
    "    label = key.split('/')[1]\n",
    "    uuid = key.split('/')[0]\n",
    "    uuids.append(uuid)\n",
    "\n",
    "    rects = detector(im, 0)\n",
    "\n",
    "    for rect in rects:\n",
    "        # convert dlib's rectangle to a OpenCV-style bounding box\n",
    "        # [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "\n",
    "        # Get rid of small faces\n",
    "        if(w < 200 and h < 200):\n",
    "            continue\n",
    "\n",
    "        face = im[y:y+h, x:x+w]\n",
    "        \n",
    "        if(face.shape[0] == 0 or face.shape[1] == 0):\n",
    "            faces[i, :] = 0\n",
    "            failed_keys.append(key)\n",
    "            continue\n",
    "        # Resize to match VGGFace requirements\n",
    "        face = cv2.resize(face, (224, 224))\n",
    "        faces[i, :] = face\n",
    "        if(label=='positive'):\n",
    "            labels[i] = 1\n",
    "        else:\n",
    "            labels[i] = 0\n",
    "\n",
    "#         cv2.imshow('image', im)\n",
    "#         ans = cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "#         if ans == ord('q'): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2728, 224, 224, 3)\n",
      "(2728,)\n",
      "04b7b555cd6d4d41bc2ec8ed6ee259e0\n"
     ]
    }
   ],
   "source": [
    "print(faces.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(failed_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array contain UUIDs of all subjects with their multiplicity\n",
    "# e.g. for one subject with 50 sample images the array will contain\n",
    "# the subjects' UUID 50 times\n",
    "uuids = []\n",
    "for i in range(DATASET_SIZE):\n",
    "    key = keys_all[i]\n",
    "    uuid = key.split('/')[0]\n",
    "    uuids.append(uuid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2728\n"
     ]
    }
   ],
   "source": [
    "print(len(uuids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many times each UUID appears\n",
    "i = 0\n",
    "len_counter = 0\n",
    "uuid_lengths = []\n",
    "\n",
    "prev_uuid = keys_all[0].split('/')[0]\n",
    "\n",
    "while i < DATASET_SIZE:\n",
    "    uuid = keys_all[i].split('/')[0]\n",
    "    if uuid == prev_uuid:\n",
    "        len_counter += 1\n",
    "    else:\n",
    "        uuid_lengths.append(len_counter)\n",
    "        len_counter = 1\n",
    "    prev_uuid = uuid\n",
    "    i += 1\n",
    "uuid_lengths.append(len_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 63, 96, 33, 97, 43, 47, 75, 29, 50, 97, 47, 88, 31, 48, 52, 20, 42, 48, 83, 49, 42, 34, 12, 40, 34, 13, 20, 81, 92, 93, 50, 93, 67, 78, 16, 33, 99, 23, 60, 100, 22, 66, 43, 82, 50, 60, 24, 22, 35, 25, 37]\n"
     ]
    }
   ],
   "source": [
    "print(uuid_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and save the features for each UUID\n",
    "start = 0\n",
    "for i in range(len(uuid_lengths)):\n",
    "    temp = features[start:start + uuid_lengths[i], :].shape[0]\n",
    "    np.save('VGG_datasets/features_' + uuids[start], temp)\n",
    "    start += uuid_lengths[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VGGFace(model='resnet50', include_top=False, pooling='avg')\n",
    "\n",
    "# features = model.predict(faces)\n",
    "\n",
    "# print(features.shape)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2)\n",
    "\n",
    "# print(X_train.shape)\n",
    "\n",
    "# svm_classifier = svm.SVC(C=1, kernel='rbf', gamma='scale')\n",
    "# svm_classifier.fit(X_train, y_train)\n",
    "# y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# print('Training set accuracy for SVM:', svm_classifier.score(X_train, y_train))\n",
    "# print('Test set accuracy for SVM: ', metrics.accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
