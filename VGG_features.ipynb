{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import face_recognition\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = glob.glob('dataset/*')\n",
    "# participants = sorted(participants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open('data_cleaned.json') as json_file:\n",
    "    data_all = json.load(json_file)\n",
    "# Extract the keys in sorted order\n",
    "keys_all = sorted(data_all)\n",
    "# Convert python list to np array\n",
    "keys_all = np.asarray(keys_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = len(keys_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detector = dlib.get_frontal_face_detector()\n",
    "# model = VGGFace(model='resnet50', include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315.3696244092002\n",
      "315.3696244092002\n",
      "262.33756879257686\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "262.33756879257686\n",
      "315.3696244092002\n",
      "314.66331212901196\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "262.33756879257686\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "262.33756879257686\n",
      "315.3696244092002\n",
      "262.33756879257686\n",
      "315.3696244092002\n",
      "262.33756879257686\n",
      "314.66331212901196\n",
      "314.66331212901196\n",
      "262.33756879257686\n",
      "262.33756879257686\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "262.33756879257686\n",
      "314.66331212901196\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "262.33756879257686\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "262.33756879257686\n",
      "314.66331212901196\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "315.3696244092002\n",
      "377.59502115361636\n",
      "315.3696244092002\n"
     ]
    }
   ],
   "source": [
    "fail_counter = 0\n",
    "for i in range(50):\n",
    "    key = keys_all[i]\n",
    "    \n",
    "    im = cv2.imread('dataset/' + key)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    label = key.split('/')[1]\n",
    "    \n",
    "    # detect the (x, y)-coordinates of the bounding boxes\n",
    "    # corresponding to each face in the input image\n",
    "    boxes = face_recognition.face_locations(im, model='hog')\n",
    "    if len(boxes) == 0:\n",
    "        print('Failed to detect faces')\n",
    "        fail_counter += 1\n",
    "        continue\n",
    "        \n",
    "    # Find the correct box assuming that it is the biggest one\n",
    "    max_dist = 0\n",
    "    for candidate_box in boxes:\n",
    "        diagonal_dist = math.sqrt(((candidate_box[0] - candidate_box[2])**2 + (candidate_box[1] - candidate_box[3])**2))\n",
    "        print(diagonal_dist)\n",
    "        if diagonal_dist >= max_dist:\n",
    "            max_dist = diagonal_dist\n",
    "            box = candidate_box\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    # compute the facial embedding for the face\n",
    "    encodings = face_recognition.face_encodings(im, [box])\n",
    "    encodings = encodings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n",
      "Failed to detect faces\n"
     ]
    }
   ],
   "source": [
    "# Loop over each participant\n",
    "fail_counter = 0\n",
    "for j in range(len(participants)):\n",
    "    \n",
    "    # Extract the UUID\n",
    "    uuid_excluded = participants[j].split('/')[1]\n",
    "\n",
    "    # Loop over the dataset to remove the examples associated with this participant\n",
    "    indices_excluded = []\n",
    "    keys_excluded = []\n",
    "    for i in range(DATASET_SIZE):\n",
    "        key = keys_all[i]\n",
    "        uuid = key.split('/')[0]\n",
    "        if(uuid == uuid_excluded):\n",
    "            indices_excluded.append(i)\n",
    "            keys_excluded.append(key)\n",
    "    \n",
    "    # Construct the validation dataset consisting of examples of a single participant\n",
    "    # Evaluation of the classifiers will be done on this dataset\n",
    "    encodings = np.zeros((len(keys_excluded), 128))\n",
    "    labels = np.zeros(len(keys_excluded))\n",
    "    \n",
    "    failed_indices = []\n",
    "    for i in range(len(keys_excluded)):\n",
    "        key = keys_excluded[i]\n",
    "\n",
    "        im = cv2.imread('dataset/' + key)\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        label = key.split('/')[1]\n",
    "\n",
    "        # detect the (x, y)-coordinates of the bounding boxes\n",
    "        # corresponding to each face in the input image\n",
    "        boxes = face_recognition.face_locations(im, model='hog')\n",
    "        if len(boxes) == 0:\n",
    "            print('Failed to detect faces')\n",
    "            failed_indices.append(i)\n",
    "            fail_counter += 1\n",
    "            continue\n",
    "\n",
    "        # Find the correct box assuming that it is the biggest one\n",
    "        max_dist = 0\n",
    "        for candidate_box in boxes:\n",
    "            diagonal_dist = math.sqrt(((candidate_box[0] - candidate_box[2])**2 + (candidate_box[1] - candidate_box[3])**2))\n",
    "            if diagonal_dist >= max_dist:\n",
    "                max_dist = diagonal_dist\n",
    "                box = candidate_box\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        # compute the facial embedding for the face\n",
    "        encoding = face_recognition.face_encodings(im, [box])[0]\n",
    "        encodings[i, :] = encoding\n",
    "    \n",
    "    encodings = np.delete(encodings, failed_indices, axis=0)\n",
    "    np.save('encodings_128/encodings_' + uuid_excluded , encodings)\n",
    "    np.save('encodings_128/labels_' + uuid_excluded, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    }
   ],
   "source": [
    "print(fail_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.14729691  0.06774978  0.05804833 -0.02481486  0.01457742 -0.13098848\n",
      "   0.03185895 -0.09281449  0.13381694 -0.02344121  0.24778102 -0.09780186\n",
      "  -0.19955719 -0.10136007  0.00547158  0.13508829 -0.15061416 -0.164839\n",
      "  -0.05453896 -0.13294765  0.11375745 -0.03479579 -0.04182607  0.05965272\n",
      "  -0.23127517 -0.29358146 -0.07965374 -0.14851795 -0.00695031 -0.09487604\n",
      "  -0.02793335  0.07085875 -0.15324566 -0.07099595  0.02489062  0.09382787\n",
      "   0.06891471 -0.02295644  0.19735321  0.00456644 -0.15250543 -0.01342253\n",
      "   0.07135649  0.3255024   0.21117303 -0.00125834  0.05611008 -0.00782865\n",
      "   0.11244152 -0.18898995  0.09594682  0.0941897   0.17605476  0.04345643\n",
      "   0.12720618 -0.15621096 -0.02702726  0.125782   -0.20915642  0.14669873\n",
      "   0.08338188 -0.09847712  0.01103789 -0.02662557  0.18027766  0.07074405\n",
      "  -0.12450655 -0.05133456  0.20990448 -0.11180948 -0.01915999  0.02039182\n",
      "  -0.14018683 -0.19755314 -0.33523273  0.06714955  0.41887984  0.11236567\n",
      "  -0.24090514  0.01563269 -0.03446953 -0.01067517  0.14426716  0.06588259\n",
      "  -0.05281895  0.01776154 -0.15840338  0.05550926  0.19822133  0.03478225\n",
      "  -0.05706214  0.18616982 -0.06447041 -0.02000645  0.03575301  0.07525953\n",
      "  -0.11968121  0.00794672 -0.08506228  0.00688571  0.02100817 -0.12039597\n",
      "  -0.009879    0.12955624 -0.13015729  0.05319608 -0.00428458  0.02396762\n",
      "  -0.14460333  0.06313175 -0.0791193  -0.03004619  0.10046322 -0.21639596\n",
      "   0.11747999  0.18365245 -0.03536101  0.12385122 -0.00172278  0.03184138\n",
      "   0.0391975  -0.02613033 -0.14931247 -0.03004175  0.00082938  0.02449735\n",
      "   0.09144323  0.09000053]\n",
      " [-0.11642949  0.05467249  0.0288809  -0.03205589  0.01175969 -0.12729084\n",
      "   0.04868029 -0.08370614  0.15867816 -0.0307814   0.23390096 -0.09117994\n",
      "  -0.18923327 -0.09679841 -0.00224161  0.11413937 -0.15087131 -0.1617938\n",
      "  -0.0592875  -0.14865367  0.08743458 -0.00195262 -0.03929556  0.04340801\n",
      "  -0.21123035 -0.28398544 -0.0986645  -0.12517567 -0.0038501  -0.05886903\n",
      "  -0.01077265  0.10484034 -0.12169191 -0.0655394   0.0617516   0.09572193\n",
      "   0.05380504 -0.02200524  0.1996143   0.0134898  -0.12014267 -0.02286629\n",
      "   0.07698056  0.35188431  0.2055157   0.00057655  0.03370852 -0.01448292\n",
      "   0.12432173 -0.17151749  0.11447116  0.09392197  0.18541293  0.0360158\n",
      "   0.15063873 -0.15217273 -0.02444571  0.1405504  -0.19244353  0.12773465\n",
      "   0.0675365  -0.12011972 -0.00677654 -0.05934966  0.16616435  0.07620852\n",
      "  -0.11237504 -0.06648629  0.21860428 -0.11834957 -0.03202701  0.01981873\n",
      "  -0.13268492 -0.1722547  -0.3128047   0.03974749  0.43061554  0.11217139\n",
      "  -0.2289777   0.02044905 -0.00569804 -0.01428034  0.15721592  0.06738632\n",
      "  -0.07582767 -0.0022109  -0.16444418  0.03462755  0.19860335  0.0317527\n",
      "  -0.08957831  0.15650961 -0.06855221 -0.00972757  0.05036426  0.02611816\n",
      "  -0.10135208  0.01702521 -0.09333225  0.00654866  0.01199711 -0.14527522\n",
      "  -0.03067097  0.11274725 -0.12726323  0.06750886  0.01868375  0.02949076\n",
      "  -0.13086897  0.04311091 -0.07618896 -0.00354343  0.11939907 -0.23610201\n",
      "   0.11044441  0.14554204 -0.02932195  0.15889105 -0.01845223  0.04509949\n",
      "   0.02360061 -0.03785761 -0.15866022 -0.038724   -0.01614789  0.02969482\n",
      "   0.09887481  0.09532652]]\n",
      "[[-0.14729691  0.06774978  0.05804833 -0.02481486  0.01457742 -0.13098848\n",
      "   0.03185895 -0.09281449  0.13381694 -0.02344121  0.24778102 -0.09780186\n",
      "  -0.19955719 -0.10136007  0.00547158  0.13508829 -0.15061416 -0.164839\n",
      "  -0.05453896 -0.13294765  0.11375745 -0.03479579 -0.04182607  0.05965272\n",
      "  -0.23127517 -0.29358146 -0.07965374 -0.14851795 -0.00695031 -0.09487604\n",
      "  -0.02793335  0.07085875 -0.15324566 -0.07099595  0.02489062  0.09382787\n",
      "   0.06891471 -0.02295644  0.19735321  0.00456644 -0.15250543 -0.01342253\n",
      "   0.07135649  0.3255024   0.21117303 -0.00125834  0.05611008 -0.00782865\n",
      "   0.11244152 -0.18898995  0.09594682  0.0941897   0.17605476  0.04345643\n",
      "   0.12720618 -0.15621096 -0.02702726  0.125782   -0.20915642  0.14669873\n",
      "   0.08338188 -0.09847712  0.01103789 -0.02662557  0.18027766  0.07074405\n",
      "  -0.12450655 -0.05133456  0.20990448 -0.11180948 -0.01915999  0.02039182\n",
      "  -0.14018683 -0.19755314 -0.33523273  0.06714955  0.41887984  0.11236567\n",
      "  -0.24090514  0.01563269 -0.03446953 -0.01067517  0.14426716  0.06588259\n",
      "  -0.05281895  0.01776154 -0.15840338  0.05550926  0.19822133  0.03478225\n",
      "  -0.05706214  0.18616982 -0.06447041 -0.02000645  0.03575301  0.07525953\n",
      "  -0.11968121  0.00794672 -0.08506228  0.00688571  0.02100817 -0.12039597\n",
      "  -0.009879    0.12955624 -0.13015729  0.05319608 -0.00428458  0.02396762\n",
      "  -0.14460333  0.06313175 -0.0791193  -0.03004619  0.10046322 -0.21639596\n",
      "   0.11747999  0.18365245 -0.03536101  0.12385122 -0.00172278  0.03184138\n",
      "   0.0391975  -0.02613033 -0.14931247 -0.03004175  0.00082938  0.02449735\n",
      "   0.09144323  0.09000053]]\n"
     ]
    }
   ],
   "source": [
    "xx = (encodings[:2, :])\n",
    "print(xx)\n",
    "print(np.delete(xx, 1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # faces = np.zeros((DATASET_SIZE, 224, 224, 3))\n",
    "# # labels = np.zeros(DATASET_SIZE)\n",
    "# failed_indices = []\n",
    "\n",
    "# for i in range(DATASET_SIZE):\n",
    "#     key = keys_all[i]\n",
    "#     im = cv2.imread('dataset/' + key)\n",
    "#     label = key.split('/')[1]\n",
    "#     uuid = key.split('/')[0]\n",
    "\n",
    "#     rects = detector(im, 0)\n",
    "    \n",
    "#     min_width, min_height = 0, 0\n",
    "#     for rect in rects:\n",
    "#         # convert dlib's rectangle to a OpenCV-style bounding box\n",
    "#         # [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "#         (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "\n",
    "#         # Get rid of small faces\n",
    "#         if(w > min_width and h > min_height):\n",
    "#             min_width, min_height = w, h\n",
    "#             face = im[y:y+h, x:x+w]\n",
    "\n",
    "#     if(face.shape[0] == 0 or face.shape[1] == 0):\n",
    "#         failed_indices.append(i)\n",
    "#         continue\n",
    "            \n",
    "#     # Resize to match VGGFace requirements\n",
    "#     face = cv2.resize(face, (224, 224))\n",
    "        \n",
    "#     faces[i, :] = face\n",
    "\n",
    "#     if(label=='positive'):\n",
    "#         labels[i] = 1\n",
    "#     else:\n",
    "#         labels[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(failed_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = np.zeros((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.predict(faces)\n",
    "features_eval = model.predict(faces_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(features_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = features, labels\n",
    "X_eval, y_eval = features_eval, labels_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier = svm.SVC(C=1, kernel='rbf', gamma='scale')\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm_classifier.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy for SVM: 0.9323364485981308\n",
      "Test set accuracy for SVM:  0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "print('Training set accuracy for SVM:', svm_classifier.score(X_train, y_train))\n",
    "print('Test set accuracy for SVM: ', metrics.accuracy_score(y_eval, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf)  # turn off summarization, line-wrapping\n",
    "f = open(\"VGG_features.txt\", \"w\") \n",
    "for row in features:\n",
    "    f.write(np.array2string(row).split('[')[1].split(']')[0] + '\\n')\n",
    "f = open(\"VGG_labels.txt\", \"w\")\n",
    "for label in labels:\n",
    "    f.write(np.array2string(label) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATASET_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fc02abec3e9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# the subjects' UUID 50 times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0muuids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfailed_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DATASET_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "# # Array contain UUIDs of all subjects with their multiplicity\n",
    "# # e.g. for one subject with 50 sample images the array will contain\n",
    "# # the subjects' UUID 50 times\n",
    "# uuids = []\n",
    "# for i in range(DATASET_SIZE):\n",
    "#     if i in failed_indices:\n",
    "#         continue\n",
    "#     key = keys_all[i]\n",
    "#     uuid = key.split('/')[0]\n",
    "#     uuids.append(uuid)\n",
    "\n",
    "# uuid_lengths = {uuid: uuids.count(uuid) for uuid in uuids}\n",
    "# uuids = sorted(uuid_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('uuid_lengths.json', 'w') as f:\n",
    "    json.dump(uuid_lengths, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uuid_lengths is a dict with uuids as keys and the number\n",
    "# of images associated with this uuid as values\n",
    "with open('uuid_lengths.json') as json_file:\n",
    "    uuid_lengths = json.load(json_file)\n",
    "\n",
    "# Load the VGG features for each example. There are 2048 features\n",
    "# for each image so features.shape = (DATASET_SIZE, 2048)\n",
    "features = np.loadtxt('VGG_features.txt')\n",
    "labels = np.loadtxt('VGG_labels.txt')\n",
    "\n",
    "uuids = sorted(uuid_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0656f5fe35a54d1589e526a702f578b0\n"
     ]
    }
   ],
   "source": [
    "print(uuid_excluded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('VGG_datasets/features_' + uuid_excluded + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2864.3257 2866.558  2845.8967 2928.418  2863.4175 2834.2725 2992.9329\n",
      " 2911.8062 2874.623  2562.122  2953.2136 2919.2275 2852.8413 2817.1284\n",
      " 2948.075  2867.8906 2884.066  2957.975  2914.134  2883.3782 2823.1348\n",
      " 2937.5815 2893.3374 2973.7566 2942.027  2891.0073 2975.7183 3012.918\n",
      " 2942.0112 2899.5078 2869.3372 2877.6182 2857.1086]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(features, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2864.3257 2866.558  2845.8967 2928.418  2863.4175 2834.2725 2992.9329\n",
      " 2911.8062 2874.623  2562.122  2953.2136 2919.2275 2852.8413 2817.1284\n",
      " 2948.075  2867.8906 2884.066  2957.975  2914.134  2883.3782 2823.1348\n",
      " 2937.5815 2893.3374 2973.7566 2942.027  2891.0073 2975.7183 3012.918\n",
      " 2942.0112 2899.5078 2869.3372 2877.6182 2857.1086]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(features_eval, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and save the features for each UUID\n",
    "start = 0\n",
    "for i in range(len(uuids)):\n",
    "    uuid = participants[i].split('/')[1]\n",
    "    current_features = features[start:start + uuid_lengths[uuid], :]\n",
    "    current_labels = labels[start:start + uuid_lengths[uuid]]\n",
    "    np.save('VGG_datasets/features_' + uuids[i], current_features)\n",
    "    np.save('VGG_datasets/labels_' + uuids[i], current_labels)\n",
    "    start += uuid_lengths[uuid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['04b7b555cd6d4d41bc2ec8ed6ee259e0', '05d77af9b4ce4de5b0f631f685601d41', '05e84e3f8e6344f5baaf003543df8d3a', '0656f5fe35a54d1589e526a702f578b0', '0c69c12c3544409f82fbcc522fb522f8', '0e55dc4aec5e442f86b809cacdec3b68', '0e7047653b014264b33c1c3620e506f8', '149797134bae4deaac692a73bf162fe9', '2cc97c9c49cb4f03ae978d1eb73f304b', '319c7f878ccb4d53948c4b338cc1732a', '36d8e15f7e164b5c980492c4c6019322', '3c243889b1c547418c69b234216cea7d', '3ef8c45b30ec40cb90526280c04dec0a', '46056754fae5429e975f17d143673451', '49102755134149d98bec4d88dec02a3c', '493e717904f744978a20292fb4adddaa', '50b8db359b164716b59c5e3a9fd001f7', '5f85582c5f1b40b48440af9c34ff3249', '61176f72b54241a2aaac74181926195a', '64a48116536441ee926f0430ca699153', '662b0d4736bf4e60858cd03cd107af90', '6ae20e8b86424bc4a624abb83aa2c9f7', '6b89f5b57aad44de9dc40896b024fad4', '744055ae2e9e4d379108bbdbfab4dae5', '7a45e3e8ed4b4774ae98254fd364f2ca', '7c6b6801ba3245bbb10dc6a7b9996d88', '7d9be1d9b22e4a229b71dbf12f339243', '8036631b52854bdda33a928371100eca', '80b077000f3442dd9aba3339a0fb237c', '80be680d12c84471a3169d1e80b5d7ec', '9329bc5c6bd24234969dfb50a1a9ca87', '9862478b2a6e4afc82af7fd08873a0b4', '9be7464cb93a49f69e6d9a330eb3715a', '9ed2ca01d30041aab1979f89cfdfa3cd', '9ef5c8cde44048f092b8625918b04986', 'a50942013ca04ebdb2f9b172ca373f2c', 'a75222d8b947422eae2b4efc35296423', 'a7f3a3a5d6764aa69a77b71dc448e5e6', 'b078965557a54caaa856046ca7c30291', 'b676104c35e54ddf9579d67765f6d4a2', 'baeac84e5d074afa9d6b7a9e9b82d8ac', 'bbdaa54f85c34395b9dd512f068a1229', 'c288292040ec473f908130877697a383', 'c308cc95412b428db8d4020a6ab826d5', 'c823b3cc2ed0484d9759cac9981031ed', 'cebaaf0546e94fcb96c1a186838a73af', 'd456335e901547d78d5a11e14155353f', 'd621bfd6fb614aa792e08d7e4cfa897a', 'd824f0d3d56f41b4946aba7c9f6c3cfd', 'e11100236f0d4c1398f1e554a3560331', 'eda516a9dbe84e00a905cce2172b30c9', 'f4e9d804730947a78e8251b35f2f519e']\n"
     ]
    }
   ],
   "source": [
    "print(uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
