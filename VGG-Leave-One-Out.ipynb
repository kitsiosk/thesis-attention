{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras_vggface.vggface import VGGFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open('data_cleaned.json') as json_file:\n",
    "    data_all = json.load(json_file)\n",
    "# Extract the keys in sorted order\n",
    "keys_all = sorted(data_all)\n",
    "# Convert python list to np array\n",
    "keys_all = np.asarray(keys_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = glob.glob('dataset/*')\n",
    "# Define global variables\n",
    "DATASET_SIZE = len(keys_all)\n",
    "NUM_OF_PARTICIPANTS = len(participants)\n",
    "DEBUG = False\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "model = VGGFace(model='resnet50', include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running attention prediction for 52 participants and a total of 2728 images.\n",
      "Each participant will be excluded from the training set once, our classifiers \n",
      "will be trained on the remaining participants and finally we will predict\n",
      "the result for the one we left out. The total accuracy will be the mean value\n",
      "of the accuracy of each participant\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"Running attention prediction for {} participants and a total of {} images.\n",
    "Each participant will be excluded from the training set once, our classifiers \n",
    "will be trained on the remaining participants and finally we will predict\n",
    "the result for the one we left out. The total accuracy will be the mean value\n",
    "of the accuracy of each participant\"\"\".format(NUM_OF_PARTICIPANTS, DATASET_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "Failed to detect face\n",
      "(2695, 224, 224, 3)\n",
      "(2695,)\n",
      "(33, 224, 224, 3)\n",
      "(33,)\n"
     ]
    }
   ],
   "source": [
    "# Accuracy metrics for the whole dataset. These are compouted\n",
    "# by leaving every Subject out one time, calculating the accuracy for each\n",
    "# one and then taking the mean value.\n",
    "accuracy_rf_total = 0\n",
    "accuracy_svm_total = 0\n",
    "precision_rf_total = 0\n",
    "precision_svm_total = 0\n",
    "recall_rf_total = 0\n",
    "recall_svm_total = 0\n",
    "\n",
    "\n",
    "# Array to keep track of subjects with low score\n",
    "low_score_subjects_rf = []\n",
    "low_score_subjects_svm = []\n",
    "\n",
    "# Loop over each participant\n",
    "for j in range(1):\n",
    "    \n",
    "    # Extract the UUID\n",
    "    uuid_excluded = participants[j].split('/')[1]\n",
    "\n",
    "    # Loop over the dataset to remove the examples associated with this participant\n",
    "    indices_excluded = []\n",
    "    keys_excluded = []\n",
    "    for i in range(DATASET_SIZE):\n",
    "        key = keys_all[i]\n",
    "        uuid = key.split('/')[0]\n",
    "        if(uuid == uuid_excluded):\n",
    "            indices_excluded.append(i)\n",
    "            keys_excluded.append(key)\n",
    "    keys = np.delete(keys_all, indices_excluded)\n",
    "    CURRENT_DATASET_SIZE = keys.shape[0]\n",
    "    \n",
    "    faces = np.zeros((CURRENT_DATASET_SIZE, 224, 224, 3))\n",
    "    labels = np.zeros(CURRENT_DATASET_SIZE)\n",
    "    \n",
    "    # Loop over each example to construct the training dataset. \n",
    "    for i in range(CURRENT_DATASET_SIZE):\n",
    "        \n",
    "        # Retrieve the key for this example\n",
    "        key = keys[i]\n",
    "        \n",
    "        # Read the image and save the size\n",
    "        im = cv2.imread('dataset/' + key)\n",
    "        size = im.shape\n",
    "        label = key.split('/')[1]\n",
    "        \n",
    "        rects = detector(im, 0)\n",
    "\n",
    "        for rect in rects:\n",
    "            # convert dlib's rectangle to a OpenCV-style bounding box\n",
    "            # [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "            (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "\n",
    "            # Get rid of small faces\n",
    "            if(w < 200 and h < 200):\n",
    "                continue\n",
    "    \n",
    "            # Crop the face\n",
    "            face = im[y:y+h, x:x+w]\n",
    "            \n",
    "            if(face.shape[0] == 0 or face.shape[1] == 0):\n",
    "                print('Failed to detect face')\n",
    "                continue\n",
    "\n",
    "            # Resize to match VGGFace requirements\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "            faces[i, :] = face\n",
    "            \n",
    "            if(label=='positive'):\n",
    "                labels[i] = 1\n",
    "            else:\n",
    "                labels[i] = 0\n",
    "    print(faces.shape)\n",
    "    print(labels.shape)\n",
    "    \n",
    "    # Construct the validation dataset consisting of examples of a single participant\n",
    "    # Evaluation of the classifiers will be done on this dataset\n",
    "    faces_eval = np.zeros((len(keys_excluded), 224, 224, 3))\n",
    "    labels_eval = np.zeros(len(keys_excluded))\n",
    "    \n",
    "    for i in range(len(keys_excluded)):\n",
    "        # Retrieve the key for this example\n",
    "        key = keys[i]\n",
    "        \n",
    "        # Read the image and save the size\n",
    "        im = cv2.imread('dataset/' + key)\n",
    "        size = im.shape\n",
    "        label = key.split('/')[1]\n",
    "        \n",
    "        rects = detector(im, 0)\n",
    "\n",
    "        for rect in rects:\n",
    "            # convert dlib's rectangle to a OpenCV-style bounding box\n",
    "            # [i.e., (x, y, w, h)], then draw the face bounding box\n",
    "            (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "\n",
    "            # Get rid of small faces\n",
    "            if(w < 200 and h < 200):\n",
    "                continue\n",
    "    \n",
    "            # Crop the face\n",
    "            face = im[y:y+h, x:x+w]\n",
    "            \n",
    "            if(face.shape[0] == 0 or face.shape[1] == 0):\n",
    "                print('Failed to detect face')\n",
    "                continue\n",
    "\n",
    "            # Resize to match VGGFace requirements\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "            faces_eval[i, :] = face\n",
    "            \n",
    "            if(label=='positive'):\n",
    "                labels_eval[i] = 1\n",
    "            else:\n",
    "                labels_eval[i] = 0\n",
    "    print(faces_eval.shape)\n",
    "    print(labels_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model.predict(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_eval = model.predict(faces_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2695, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = features, labels\n",
    "X_eval, y_eval = features_eval, labels_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_classifier = svm.SVC(C=1, kernel='rbf', gamma='scale')\n",
    "svm_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm_classifier.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy for SVM: 0.9424860853432282\n",
      "Test set accuracy for SVM:  0.9696969696969697\n"
     ]
    }
   ],
   "source": [
    "print('Training set accuracy for SVM:', svm_classifier.score(X_train, y_train))\n",
    "print('Test set accuracy for SVM: ', metrics.accuracy_score(y_eval, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
